{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an XGBoost model\n",
    "\n",
    "The focus of this is to train a model in one dataset and try to predict in another from a fifferent cell line. My interest here is to check if I can improve our ability to classify by using the k-mer scores as follows:\n",
    " - Create a possitive and a negative set from one ChIP-seq cell lines\n",
    "     - Score the sequence using:\n",
    "         - E-scores\n",
    "         - frequency difference\n",
    "         - a kmer-based model generated by training the sequences / using kmer counts of all the 8-mers in each set\n",
    "         \n",
    "     - Additional features:\n",
    "         - DNA shape\n",
    "         - Proximity to TSS\n",
    "         - Evolutionary conservation\n",
    "     - Train a model using the above features\n",
    "     - Use the model generated to classify a given set of sequences\n",
    "     - Performm feature importance studies\n",
    " \n",
    " To achevive the above, the following functions are needed:\n",
    "     1. A scoring function for all the sequences\n",
    "     2. A quick way to get the counts of the k-mers\n",
    "     3. A quick way to get the DNA-shape features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import  exp\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pybedtools\n",
    "import pyBigWig\n",
    "import pysam\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Main SVM module and grid search function\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "#For partitioning the data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "#Libsvm format data loading\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "#Accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc\n",
    "\n",
    "# Creating an learning pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the core functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from XGB_TFBSContext import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First set the path to essential, but large files\n",
    "\n",
    "### 1. The DNA Shape files\n",
    "Downloaded from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_path = \"/home/kipkurui/Dream_challenge/DNAShape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The human genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_genome = \"/home/kipkurui/Dream_challenge/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Uniformly processed ChIP-seq peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chipseq_path = \"/home/kipkurui/Project/MARS/Data/ChIP-seq/Downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BASE_DIR = \"/home/kipkurui/Dream_challenge/DreamChallenge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create kmer dictionaries for the features of interest\n",
    "We have two option here:\n",
    "1. Backround noise scalled in a simiklar maner to sticky k-mers \n",
    "1. Preferred k-mers max normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dn_hg_dict, kmer_name = get_kmer_dict_rev(\"Data/dn_hg_max_normalized.txt\", \"test\")\n",
    "\n",
    "dn_hg_dict2, kmer_name = get_kmer_dict_rev(\"Data/hg_dn_backround_noise_minmax.txt\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Score the sequences of interest\n",
    "\n",
    "#### a) K_mer score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all data prepapration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_df(tf, pos):\n",
    "    \"\"\"\n",
    "    Given a TF and the position of the peak file of interest\n",
    "    Creat a DataFrame with all the coordinates\n",
    "    \n",
    "    This is the main Feature Vector\n",
    "    \"\"\"\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    ## Calculate all the necessary features\n",
    "    #E_score_combined = get_kmer_score(combined_bed, sum_kmer_score, E_score_dict)\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame[\"sum_kmer_score\"] = get_kmer_score(combined_bed, sum_kmer_score, E_score_dict)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"hg_dn_score\"] = get_kmer_score(combined_bed, max_score_kmer, hg_dn_dict)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete Feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_list = ['max_kmer_score','dnase','kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos','dn_hg_score',\n",
    " 'dn_hg_score2',\"tss_dist\", \"phyloP100way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pop_this(feat):\n",
    "    try:\n",
    "        all_feats.pop(all_feats.index(feat))\n",
    "    except ValueError:\n",
    "        try:\n",
    "            for i in range(8):\n",
    "                all_feats.pop(all_feats.index(feat+\"_%i\" % i))\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the different machine learning models\n",
    "\n",
    "A stand-alone implementation of this is *test_xgb_svm_gbc_sgd.py*\n",
    "\n",
    "Using this note, we can test a variety of machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_sgd(feature_frame, feature_frame_p, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    #Scale the train data\n",
    "    scaler.fit(feature_frame) \n",
    "    X_train = scaler.transform(feature_frame)\n",
    "\n",
    "    #Scale the test data as well\n",
    "    scaler.fit(feature_frame_p)\n",
    "    X_test = scaler.transform(feature_frame_p)\n",
    "    \n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred_sgd = clf.predict(X_test)\n",
    "    \n",
    "    return roc_auc_score(y_test, pred_sgd)\n",
    "\n",
    "def train_svm(feature_frame, feature_frame_p, y_train, y_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    #Scale the train data\n",
    "    scaler.fit(feature_frame) \n",
    "    X_train = scaler.transform(feature_frame)\n",
    "\n",
    "    #Scale the test data as well\n",
    "    scaler.fit(feature_frame_p)\n",
    "    X_test = scaler.transform(feature_frame_p)\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred_svm = clf.predict(X_test)\n",
    "    \n",
    "    return roc_auc_score(y_test, pred_svm)\n",
    "\n",
    "def train_xgb(feature_frame,feature_frame_p,y_train, y_test):\n",
    "    \n",
    "    xgdmat = xgb.DMatrix(feature_frame, y_train) \n",
    "    our_params = {'eta': 0.3, 'seed':0, 'subsample': 1, 'colsample_bytree': 1, \n",
    "                 'objective': 'binary:logistic', 'max_depth':6, 'min_child_weight':1} \n",
    "    my_model = xgb.train(our_params,xgdmat)\n",
    "    testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "    y_pred = my_model.predict(testdmat)\n",
    "    \n",
    "    return roc_auc_score(y_test, y_pred)\n",
    "\n",
    "def train_gradient(feature_frame,feature_frame_p,y_train, y_test):\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(feature_frame, y_train)\n",
    "    pred_sgd = clf.predict(feature_frame_p)\n",
    "\n",
    "    return roc_auc_score(y_test, pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/test.txt\", \"w\") as tf_scores:\n",
    "    \n",
    "    tf_scores.write(\"Tf_name\\t\")\n",
    "    for j in \"sgd, svms, xgboost, gradient\".split():\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in [\"Max\"]:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "        \n",
    "        #Ensure the disk is not filled up by temp files\n",
    "        pybedtools.cleanup()\n",
    "        feature_frame = feature_frame.fillna(0)\n",
    "        feature_frame_p = feature_frame_p.fillna(0)\n",
    "        \n",
    "        sgd = train_sgd(feature_frame, feature_frame_p, y_train, y_test)\n",
    "        svms = train_svm(feature_frame, feature_frame_p, y_train, y_test)\n",
    "        xgboost = train_xgb(feature_frame, feature_frame_p, y_train, y_test)\n",
    "        gradient = train_gradient(feature_frame, feature_frame_p, y_train, y_test)\n",
    "        \n",
    "        for mod in [sgd, svms, xgboost, gradient]:\n",
    "            tf_scores.write(\"%.4f\\t\" % mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train a model using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    \n",
    "    tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    for j in feat_list:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_best(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_best(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in feat_list:\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pbm_chip = []\n",
    "pbmchip2name = {}\n",
    "with open(\"../Data/Pbm_Chip_details.txt\") as pbmnchip:\n",
    "    for line in pbmnchip:\n",
    "        if line.startswith('Tf_id'):\n",
    "            continue\n",
    "        else:\n",
    "            pbm_chip.append(line.split()[0])\n",
    "            pbmchip2name[line.split()[1]] = line.split()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of TFs affected by Sticky k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sticky_tfs = pd.read_table(\"../Data/names.txt\", header=None)\n",
    "tf_list = []\n",
    "for tf in sticky_tfs[0]:\n",
    "    #Needs ChIp-seq files converted to posneg format. Provide path here\n",
    "    chip_list = glob.glob(\"../Data/ChIP-seq/Derived/Posneg/%s/*\" % tf.capitalize())\n",
    "    if len(chip_list) > 0:\n",
    "        tf_list.append(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_list = ['Foxa2', 'Gata3', 'Max', 'Tcf3', 'Tcf7l2', 'Irf3', 'Irf4',\n",
    " 'Hnf4a', 'Nr2f2', 'Rxra', 'Egr1', 'Sp4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of Tfs available in PBM and ChIP with more than two peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_pbm = pd.read_table(\"../Data/Pbm_Chip_details.txt\")\n",
    "\n",
    "in_both = tf_pbm[(tf_pbm[\"Chip_name\"] >0) == (tf_pbm[\"Pbm_name\"] >0)]\n",
    "chip_name = tf_pbm[(tf_pbm[\"Chip_name\"] >0)][\"Chip_name\"]\n",
    "chip_name = chip_name.sort_values()\n",
    "\n",
    "in_both_new = []\n",
    "for tf in chip_name:\n",
    "    if (len(get_contigmers(tf)) > 0) & (len(get_peak_files(tf)) > 1):\n",
    "        #print get_contigmers(tf)\n",
    "        in_both_new.append(tf)\n",
    "#Remove Taf1 -- Wrongly picked above\n",
    "in_both_new.pop(in_both_new.index(\"Taf1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_both_new2 = ['Ap2', 'Arid3a', 'Egr1', 'Elk1', 'Elk4', 'Ets1', 'Gabp', 'Gata3',\n",
    " 'Gr', 'Hnf4a', 'Irf3', 'Jund', 'Mafk', 'Max', 'Pou2f2', 'Rxra', 'Sp1', 'Srf',\n",
    " 'Tbp', 'Tcf7l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = ['max_kmer_score',\"phatsCons\",'dn_hg_score','dnase', \"tss_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_list = [\n",
    " 'max_kmer_score',\"phatsCons\",\n",
    " 'dn_hg_score2',\n",
    " 'dnase', \"tss_dist\", \"phyloP100way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overal_list = []\n",
    "for feat in feat_list:\n",
    "    feats = feat_list[:]\n",
    "    feats.pop(feats.index(feat))\n",
    "    overal_list.append(feats[:])\n",
    "for feat1 in feat_list:\n",
    "    new_l = [feat1]\n",
    "    for feat in feat_list:\n",
    "        if not feat in new_l:\n",
    "            new_l.append(feat)\n",
    "            new_l.sort()\n",
    "            add_in = new_l[:]\n",
    "            if add_in not in overal_list:\n",
    "                overal_list.append(add_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/feature_details_importance\", \"w\") as feats:   \n",
    "    for j, yu in enumerate(overal_list):\n",
    "        #print feat_list[j]+\"_\"+str(j)\n",
    "        feats.write(\"AUC_%i\\t %s\\n\" % (j, '|'.join(yu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_best6(tf, pos):\n",
    "    \"\"\"\n",
    "    Given a TF and the position of the peak file of interest\n",
    "    Creat a DataFrame with all the coordinates\n",
    "    \n",
    "    This is the main Feature Vector\n",
    "    \"\"\"\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"hg_dn_score\"] = get_kmer_score(combined_bed, max_score_kmer, hg_dn_dict)\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature importance by eliminating one, sequentially\n",
    "\n",
    "The shape features will have to be eliminated together as a group.This is an attempt to be clear on the contribution to the accuracy by each of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    \n",
    "    #tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in tf_list:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_best(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_best(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in feat_list:\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature importance by recursive addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    feat_list = ['sum_kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos','dn_hg_score',\n",
    " 'hg_dn_score',\"tss_dist\", \"phyloP100way\"]\n",
    "    for j in feat_list:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs: #in_both_new:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "#         #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_df(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_df(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "#         #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        feat_list = ['sum_kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos','dn_hg_score',\n",
    " 'hg_dn_score',\"tss_dist\", \"phyloP100way\"]\n",
    "        loop_this = feat_list[:]\n",
    "        for i,j in enumerate(loop_this):\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            feat_list = ['sum_kmer_score',\"phatsCons\",\n",
    "             'Roll', 'ProT', 'MGW', 'HelT',\n",
    "             'max_kmer_score_pos','dn_hg_score',\n",
    "             'hg_dn_score',\"tss_dist\", \"phyloP100way\"]\n",
    "            #print i,j\n",
    "            feat_list.pop(i)\n",
    "\n",
    "            for i in feat_list:\n",
    "                pop_this(i)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can confidently deduce that the most informative feature as DNase and TSS; however, for other features, we lose information on the quality of the model since *k*-mer scores are will not be confidently measured. Therefore, we eliminate the poorly performing features and then introduce. \n",
    "\n",
    "### 7. Contribution of the DNA shape to the baseline model\n",
    "\n",
    "Here, we will have a complete feature with:\n",
    "* The max *k*-mer score\n",
    "* The DNase score\n",
    "* The Each of the Shape features\n",
    "\n",
    "So the Idea is to start with a complete model, then one with a  variation of each of the shape features. \n",
    "\n",
    "The difficulty with these is that the model does not consider the order of the features, rather, it starts with the first ones and moves along with the rest. So, the feature presented first seems to have a high contribution to the tree decisions. \n",
    "\n",
    "Here we want to observe the contribution, rather than how much a dip is adding the feature causes. Then decide on the input of each of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_df_shape(tf, pos):   \n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_shape3.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\tNone\\t\")\n",
    "    for j in [ 'Roll', 'ProT', 'MGW', 'HelT']:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs:#in_both_new[17:]:\n",
    "        shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_df_shape(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_df_shape(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for i in shapes:\n",
    "            pop_this(i)\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        for i,j in enumerate([ 'Roll', 'ProT', 'MGW', 'HelT']):\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']\n",
    "            #print i,j\n",
    "            shapes.pop(i)\n",
    "\n",
    "            for i in shapes:\n",
    "                pop_this(i)\n",
    "    \n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "\n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test the effect of the preferred and noise *k*-mer scores as an additional feature\n",
    "\n",
    "The question here is to determine if it does contribute to the predictive ability of the model. Here we can extract the information from the feature contribution based on how much loss it causes. \n",
    "\n",
    "Here, we also want to use the baseline model comprising of the DNase and kmer scores; that is after determining the best scoring function we just settle on that for any subsequent computation. The level of correlation of the various features is also informative regarding how much more value they can add to the quality of the model. \n",
    "\n",
    "With this, the best option is to test the performance of the baseline with *k*-mer model and with DNase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_features = [[\"dnase\", \"max_kmer_score\",\"dn_hg_score\",\"hg_dn_score\"],[\"dnase\", \"max_kmer_score\"],[\"dnase\", \"max_kmer_score\",\"hg_dn_score\"], [\"dnase\", \"max_kmer_score\",\"dn_hg_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_noise(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_noise.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\tNone\\tNoise\\tPreferred\\t\")\n",
    "    for j in feat_list:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in in_both_new:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_noise(tf, 0)\n",
    "        #for pos in range(1,len(get_peak_files(tf)))\n",
    "        feature_frame_p,trim_to_p =  get_feature_noise(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in noise_features:\n",
    "            my_model = train_xgboost(feature_frame[feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test how well the models can be generalizable to other cell lines\n",
    "\n",
    "To do this, I need to identify those TFS that have data in more than three cell lines, then use that information to test how a model trained in a rotating manner can be utilised top predict binding in the other cell lines and, what is the accuracy. Although in a way, our current implementation where we train in one and test in another is okay, we need to check and see if there exist fluctuations in performance depending on the training cell line. \n",
    "\n",
    "Given a TF with more than one cell line, we get the name and then test prediction ability of a model from one cell line in predicting performance in another cell line.\n",
    "* Start with single cell line, and if we do observe some irregularities, then --\n",
    "* Create a  model from each of the cell lines testing the performance in the other cell lines. \n",
    "* Determine how well we can generalise our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_3 = []\n",
    "for tf in in_both_new:\n",
    "    #print tf\n",
    "    peak_files = get_peak_files(tf)\n",
    "    if (len(peak_files) > 3) & (len(peak_files) < 10):\n",
    "        over_3.append(tf)\n",
    "    #print get_celltype(peak_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_celltype(peak_files):\n",
    "    cell_types = []\n",
    "    for i in range(len(peak_files)):\n",
    "        cell_types.append(peak_files[i].split(\"/\")[-1].split(\"Tfbs\")[-1].split(\"UniPk\")[0])\n",
    "    return cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_cell_type(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"hg_dn_score\"] = get_kmer_score(combined_bed, max_score_kmer, hg_dn_dict)\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_cell_type_specificity_1.txt\", \"a\") as tf_scores:\n",
    "    for tf in over_3:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_cell_type(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        my_model = train_xgboost(feature_frame, y_train, tf)\n",
    "        for pos in range(0,len(get_peak_files(tf))-1):\n",
    "            feature_frame_p,trim_to_p =  get_feature_cell_type(tf, pos)\n",
    "\n",
    "            y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "\n",
    "            all_feats = list(feature_frame.columns)\n",
    "\n",
    "            testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the different training cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over_3 = ['Gabp', 'Gata3', 'Jund', 'Mafk', 'Max', 'Sp1', 'Srf', 'Tbp', 'Tcf7l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_cell_type_specificity_recursive.txt\", \"a\") as tf_scores:\n",
    "    for tf in over_3:\n",
    "        tf_scores.write(\"\\n%s\\n\" % tf)\n",
    "        print tf\n",
    "        for train in range(len(get_peak_files(tf))):\n",
    "            pybedtools.cleanup()\n",
    "            tf_scores.write(\"%s\\t\" % get_celltype(get_peak_files(tf))[train])\n",
    "            feature_frame, trim_to = get_feature_cell_type(tf, train)\n",
    "            y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "            my_model = train_xgboost(feature_frame, y_train, tf)\n",
    "            for pos in range(len(get_peak_files(tf))):\n",
    "                feature_frame_p,trim_to_p =  get_feature_cell_type(tf, pos)\n",
    "\n",
    "                y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "\n",
    "                all_feats = list(feature_frame.columns)\n",
    "\n",
    "                testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "\n",
    "                y_pred = my_model.predict(testdmat)\n",
    "\n",
    "                tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Test for conservation data contribution\n",
    "\n",
    "Using the same idea, we need to test the various forms of acquiring the conservation scores and their effect on the performance of the model. Here are to test the following:\n",
    "* Phastcons hit\n",
    "* Phastcons whole site\n",
    "* Phylo hit\n",
    "* phylo whole site\n",
    "\n",
    "With each of these, we use the baseline model already defined and tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_conservation(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"phatsCons_whole\"] = apply_get_phatscon(combined_bed)\n",
    "    feature_frame[\"phyloP100way_whole\"] = apply_get_phatscon(combined_bed, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conservation_features = [[\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                  [\"dnase\", \"max_kmer_score\"],\n",
    "                  [\"dnase\", \"max_kmer_score\",\"phyloP100way\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                  [\"dnase\", \"max_kmer_score\",\"phatsCons\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                 [\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\",\"phyloP100way_whole\"],\n",
    "                 [\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\", \"phatsCons_whole\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../Results/TF_scores_feature_importance_recursive_conservation.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\tNone\\tPhats_hit\\tPhylo_hit\\tPhats_wh\\tPhylo_wh\\t\")\n",
    "    for tf in tf_list:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_conservation(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_conservation(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        for feats in conservation_features:\n",
    "            my_model = train_xgboost(feature_frame[feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.fit(feature_frame, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9]}\n",
    "ind_params = {'n_estimators': 1000, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 1}\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "optimized_GBM.fit(feature_frame, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'subsample': [0.7, 0.8, 0.9], 'learning_rate': [0.1, 0.01]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)\n",
    "\n",
    "[mean: 0.82907, std: 0.02203, params: {'max_depth': 3, 'min_child_weight': 1},\n",
    " mean: 0.82895, std: 0.02155, params: {'max_depth': 3, 'min_child_weight': 3},\n",
    " mean: 0.82891, std: 0.02206, params: {'max_depth': 3, 'min_child_weight': 5},\n",
    " mean: 0.82663, std: 0.02266, params: {'max_depth': 5, 'min_child_weight': 1},\n",
    " mean: 0.82706, std: 0.02249, params: {'max_depth': 5, 'min_child_weight': 3},\n",
    " mean: 0.82644, std: 0.02345, params: {'max_depth': 5, 'min_child_weight': 5},\n",
    " mean: 0.82056, std: 0.02175, params: {'max_depth': 7, 'min_child_weight': 1},\n",
    " mean: 0.81939, std: 0.02062, params: {'max_depth': 7, 'min_child_weight': 3},\n",
    " mean: 0.82089, std: 0.02104, params: {'max_depth': 7, 'min_child_weight': 5}]\n",
    "\n",
    "\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'subsample': [0.7, 0.8, 0.9], 'learning_rate': [0.1, 0.01]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)\n",
    "\n",
    "#learning rate\n",
    "\n",
    "[mean: 0.82960, std: 0.02174, params: {'subsample': 0.7, 'learning_rate': 0.1},\n",
    " mean: 0.82907, std: 0.02203, params: {'subsample': 0.8, 'learning_rate': 0.1},\n",
    " mean: 0.82858, std: 0.02144, params: {'subsample': 0.9, 'learning_rate': 0.1},\n",
    " mean: 0.82084, std: 0.01890, params: {'subsample': 0.7, 'learning_rate': 0.01},\n",
    " mean: 0.82065, std: 0.01878, params: {'subsample': 0.8, 'learning_rate': 0.01},\n",
    " mean: 0.82001, std: 0.01869, params: {'subsample': 0.9, 'learning_rate': 0.01}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_frame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(feature_frame, y_train) # Create our DMatrix to make XGBoost more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':1} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
