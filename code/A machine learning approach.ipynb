{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an SVM or XGBoost model\n",
    "\n",
    "The focus of this is to train a model in one dataset and try to predict in another from a fifferent cell line. My interest here is to check if I can improve our ability to classify by using the k-mer scores as follows:\n",
    " - Create a possitive and a negative set from one ChIP-seq cell line\n",
    "     - Score the sequence using:\n",
    "         - E-scores\n",
    "         - frequency difference\n",
    "         - a kmer based model generated by training the sequences / using kmer counts of all the 8-mers in each set\n",
    "     - Use the model generated to classify a given set of sequences\n",
    " \n",
    " The next question is, wha kind of codes do we need:\n",
    "     1. A scoring function for all the sequences\n",
    "     2. A quick way to get the counts of the k-mers / have a look at how some previous challenges have used this approach\n",
    "     3. A quick way to get the DNA-shape features: This will require choosing a portion of the highest scoring window to use\n",
    "     4. Test the above features first, and then see if we can expand this to other features\n",
    "     \n",
    "     \n",
    "To be able to achieve all the above, we will need to get an indepth understanding of what we are doing, the algorithm we will use, and how much we will end up doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import  exp\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pybedtools\n",
    "import pyBigWig\n",
    "import pysam\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Main SVM module and grid search function\n",
    "from sklearn import svm, grid_search\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "#For partitioning the data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "\n",
    "#Libsvm format data loading\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "#Accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc\n",
    "\n",
    "# Creating an learning pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First set the path to essential, but large files\n",
    "\n",
    "### 1. The DNA Shape files\n",
    "Downloaded from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_path = \"/home/kipkurui/Dream_challenge/DNAShape\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The human genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_genome = \"/home/kipkurui/Dream_challenge/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Uniformly processed ChIP-seq peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chipseq_path = \"/home/kipkurui/Project/MARS/Data/ChIP-seq/Downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tau_file =\"/home/kipkurui/Project/Data/Clean/hg_dn_backround_noise3.txt\"\n",
    "# tau_2 = pd.read_table(tau_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tau_file = \"/home/kipkurui/Project/Others_work/Bayesian_PBM_Analysis/Bayesian_PBM_Analysis/background_example/estimated_noise.txt\"\n",
    "# tau = pd.read_table(tau_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tau_2 * 0.151863\n",
    "#((tau_2 * 0.151863) * 0.151863).sort_values(by=0, ascending=False)\n",
    "#(tau * 0.151863).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some universally useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "revcompl = lambda x: ''.join([{'A':'T','C':'G','G':'C','T':'A'}[B] for B in x][::-1])\n",
    "\n",
    "def score_kmer(kmer,kmerdict,revcompl):\n",
    "    score=0\n",
    "    if kmer in kmerdict:\n",
    "        score=float(kmerdict[kmer])\n",
    "    else:\n",
    "        kmer2=revcompl(kmer)\n",
    "        score=float(kmerdict[kmer2])\n",
    "    return score\n",
    "\n",
    "def energy_score_kmer(kmerdict, seq):\n",
    "    k_mers = find_kmers(seq, 8)\n",
    "    tot_score = 0\n",
    "    for kmer in k_mers:\n",
    "        if kmer in kmerdict:\n",
    "            score = float(kmerdict[kmer])\n",
    "        else:\n",
    "            score = 0.0\n",
    "            #kmer2 = revcompl(kmer)\n",
    "            #score = float(kmerdict[kmer2])\n",
    "        tot_score += score\n",
    "    return tot_score\n",
    "\n",
    "def max_score_kmer(kmerdict, seq):\n",
    "    k_mers = find_kmers(seq, 8)\n",
    "    tot_score = []\n",
    "    for kmer in k_mers:\n",
    "        if kmer in kmerdict:\n",
    "            score = float(kmerdict[kmer])\n",
    "        else:\n",
    "            score = 0.0\n",
    "            #kmer2 = revcompl(kmer)\n",
    "            #score = float(kmerdict[kmer2])\n",
    "        tot_score.append(score)\n",
    "    return max(tot_score)\n",
    "\n",
    "\n",
    "def max_score_kmer_pos(kmerdict, seq):\n",
    "    k_mers = find_kmers(seq, 8)\n",
    "    tot_score = []\n",
    "    for kmer in k_mers:\n",
    "        if kmer in kmerdict:\n",
    "            score = float(kmerdict[kmer])\n",
    "        else:\n",
    "            score = 0.0\n",
    "            #kmer2 = revcompl(kmer)\n",
    "            #score = float(kmerdict[kmer2])\n",
    "        tot_score.append(score)\n",
    "    max_pos = tot_score.index(max(tot_score))\n",
    "    \n",
    "    return sum(tot_score[max_pos-4:max_pos+4]), max_pos-4\n",
    "\n",
    "\n",
    "def energyscore(pwm_dictionary, seq):\n",
    "    \"\"\"\n",
    "    Score sequences using the beeml energy scoring approach.\n",
    "\n",
    "    Borrowed greatly from the work of Zhao and Stormo\n",
    "\n",
    "    P(Si)=1/(1+e^Ei-u)\n",
    "\n",
    "    Ei=sumsum(Si(b,k)e(b,k))\n",
    "\n",
    "    Previous approaches seem to be using the the minimum sum of the\n",
    "    energy contribution of each of the bases of a specific region.\n",
    "\n",
    "    This is currently showing some promise but further testing is\n",
    "    needed to ensure that I have a robust algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    energy_list = []\n",
    "    pwm_length = len(pwm_dictionary[\"A\"])\n",
    "    pwm_dictionary_rc = rc_pwm(pwm_dictionary, pwm_length)\n",
    "    for i in range(len(seq) - 1):\n",
    "        energy = 0\n",
    "        energy_rc = 0\n",
    "        for j in range(pwm_length - 1):\n",
    "            if (j + i) >= len(seq):\n",
    "                energy += 0.25\n",
    "                energy_rc += 0.25\n",
    "            else:\n",
    "                energy += pwm_dictionary[seq[j + i]][j]\n",
    "                energy_rc += pwm_dictionary_rc[seq[j + i]][j]\n",
    "\n",
    "            energy_list.append(1 / (1 + (exp(energy))))\n",
    "            energy_list.append(1 / (1 + (exp(energy_rc))))\n",
    "    energy_score = min(energy_list)\n",
    "    return energy_score\n",
    "\n",
    "# def energy_score_kmer(seq,kmerdict,revcompl):\n",
    "#     k_mers=find_kmers(seq,8)\n",
    "#     tot_score = 0\n",
    "#     for kmer in k_mers:\n",
    "#         if kmer in kmerdict:\n",
    "#             score=float(kmerdict[kmer])\n",
    "#         else:\n",
    "#             kmer2=revcompl(kmer)\n",
    "#             score=float(kmerdict[kmer2])\n",
    "#         tot_score+=score\n",
    "#     return tot_score\n",
    "\n",
    "def find_kmers(string, kmer_size):\n",
    "    kmers = []\n",
    "    for i in range(0, len(string)-kmer_size+1):\n",
    "        kmers.append(string[i:i+kmer_size])\n",
    "    return kmers\n",
    "\n",
    "def getKey(item):\n",
    "    return item[1]\n",
    "\n",
    "def get_kmer_dict(kmerscore, kmer_name):\n",
    "    scoredict={}\n",
    "    with open(kmerscore) as kmers:\n",
    "        for line in kmers:\n",
    "            ke,rem, val=line.split()\n",
    "            scoredict[ke]=val\n",
    "    return scoredict, kmer_name\n",
    "\n",
    "def get_kmer_dict_rev(kmerscore, kmer_name):\n",
    "    \"\"\"\n",
    "    Convert the forward and reverse kmers into a dictionary\n",
    "    for a quick look-up and scoring of sequences\n",
    "    \"\"\"\n",
    "    test = pd.read_table(kmerscore, index_col=\"8-mer\", usecols=[\"8-mer\", \"E-score\"])\n",
    "    test.fillna(0, inplace=True)\n",
    "    test2 = pd.read_table(kmerscore, index_col=\"8-mer.1\", usecols=[\"8-mer.1\", \"E-score\"])\n",
    "    test2.index.name = \"8-mer\"\n",
    "    test2.fillna(0, inplace=True)\n",
    "    combined = test.append(test2)\n",
    "    combined_dict = combined.to_dict()[\"E-score\"]\n",
    "\n",
    "    return combined_dict, kmer_name\n",
    "\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "# Sequence scoring  in parallel  \n",
    "def score_from_genome(bed_df):\n",
    "    \n",
    "    return bed_df.apply(lambda row: fetch_and_score_seq(row[0], row[1], row[2]), axis=1)\n",
    "\n",
    "def fetch_and_score_seq(contig, start, end):\n",
    "    genome = pysam.FastaFile('%s/hg19.genome.fa' % human_genome)\n",
    "    return score_function(pwm_dictionary, genome.fetch(contig, start, end).upper())\n",
    "\n",
    "\n",
    "# def score_from_genome_shape(bed_df):\n",
    "    \n",
    "#     return bed_df.apply(lambda row: fetch_and_score_seq_shape(row[0], row[1], row[2]), axis=1)\n",
    "\n",
    "# def fetch_and_score_seq_shape(contig, start, end):\n",
    "#     genome = pysam.FastaFile('/home/kipkurui/Dream_challenge/annotations/hg19.genome.fa')\n",
    "#     return score_function(pwm_dictionary, genome.fetch(contig, start, end).upper())\n",
    "\n",
    "def get_full_shape(shape_file, ch, start, end):\n",
    "    \"\"\"\n",
    "    Extract the shape information from the full length TFBS\n",
    "    as opposed to mean\n",
    "    \"\"\"\n",
    "    bw = pyBigWig.open(shape_file)\n",
    "    \n",
    "    return bw.values(ch, start, end)\n",
    "\n",
    "def apply_get_full_shape(bed_df, shape=\"Roll\"):\n",
    "    \"\"\"\n",
    "    Keep it this way for now, but when I have to parallelize,\n",
    "    I will have to think differently\n",
    "    \"\"\"\n",
    "    shape_file = \"%s/hg19.%s.wig.bw\" % (shape_path, shape)\n",
    "    test = bed_df.apply(lambda row: get_full_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "    mean_shape = test.fillna(0)\n",
    "    \n",
    "    return mean_shape\n",
    "\n",
    "def get_mean_shape(shape_file, ch, start, end):\n",
    "    \"\"\"\n",
    "    Extract the maximum fold enrichment from Bigwig files\n",
    "    \n",
    "    Keep in mind this error:\n",
    "    \"An error occurred while fetching values!\"\n",
    "    \n",
    "    This error lead to incorrect results. \n",
    "    Will have to re-think way out latter\n",
    "    \n",
    "    SOLVED: The file cannot be accessed concerrently. \n",
    "    Should open a new file handle\n",
    "    for each run. \n",
    "    \"\"\"\n",
    "    bw = pyBigWig.open(shape_file)\n",
    "    try:\n",
    "        return np.mean(bw.values(ch, start, end))\n",
    "    except RuntimeError:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def apply_get_shape(bed_df, shape=\"Roll\"):\n",
    "    \"\"\"\n",
    "    Keep it this way for now, but when I have to parallelize,\n",
    "    I will have to think differently\n",
    "    \"\"\"\n",
    "    shape_file = \"%s/DNAShape/hg19.%s.wig.bw\" % (shape_path, shape)\n",
    "    test = bed_df.apply(lambda row: get_mean_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "    mean_shape = test.fillna(0)\n",
    "    \n",
    "    return mean_shape\n",
    "# def get_mean_shape(ch, start, end):\n",
    "#     \"\"\"\n",
    "#     Extract the maximum fold enrichment from Bigwig files\n",
    "    \n",
    "#     Keep in mind this error:\n",
    "#     \"An error occurred while fetching values!\"\n",
    "    \n",
    "#     This error lead to incorrect results. \n",
    "#     Will have to re-think way out latter\n",
    "    \n",
    "#     SOLVED: The file cannot be accessed concerrently. \n",
    "#     Should open a new file handle\n",
    "#     for each run. \n",
    "#     \"\"\"\n",
    "#     bw = pyBigWig.open(\"/home/kipkurui/Dream_challenge/DNAShape/hg19.%s.wig.bw\" % shape)\n",
    "#     try:\n",
    "#         return np.mean(bw.values(ch, start, end))\n",
    "#     except RuntimeError:\n",
    "#         return 0\n",
    "\n",
    "# def apply_get_shape(bed_df):\n",
    "#     \"\"\"\n",
    "#     Get max DNase fold enrichment over the whole\n",
    "#     dataframe using pandas apply function\n",
    "#     \"\"\"\n",
    "#     test = bed_df.apply(lambda row: get_mean_shape(row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "#     mean_shape = test.fillna(0)\n",
    "    \n",
    "#     return mean_shape\n",
    "\n",
    "\n",
    "# def apply_get_shape_Roll(bed_df):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     shape_file = \"%s/hg19.%s.wig.bw\" % (shape_path,shape)\n",
    "#     test = bed_df.apply(lambda row: get_mean_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "#     mean_shape = test.fillna(0)\n",
    "    \n",
    "#     return mean_shape\n",
    "\n",
    "# def apply_get_shape_HelT(bed_df):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     shape_file = \"%s/DNAShape/hg19.HelT.wig.bw\" % BASE_DIR\n",
    "#     test = bed_df.apply(lambda row: get_mean_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "#     mean_shape = test.fillna(0)\n",
    "    \n",
    "#     return mean_shape\n",
    "\n",
    "# def apply_get_shape_ProT(bed_df):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     shape_file = \"%s/DNAShape/hg19.ProT.wig.bw\" % BASE_DIR\n",
    "#     test = bed_df.apply(lambda row: get_mean_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "#     mean_shape = test.fillna(0)\n",
    "    \n",
    "#     return mean_shape\n",
    "\n",
    "# def apply_get_shape_MGW(bed_df):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     shape_file = \"%s/DNAShape/hg19.MGW.wig.bw\" % BASE_DIR\n",
    "#     test = bed_df.apply(lambda row: get_mean_shape(shape_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "#     mean_shape = test.fillna(0)\n",
    "    \n",
    "#     return mean_shape\n",
    "\n",
    "def get_max_dnase(ch, start, end):\n",
    "    \"\"\"\n",
    "    Extract the maximum fold enrichment from Bigwig files\n",
    "    \n",
    "    Keep in mind this error:\n",
    "    \"An error occurred while fetching values!\"\n",
    "    \n",
    "    This error lead to incorrect results. \n",
    "    Will have to re-think way out latter\n",
    "    \n",
    "    SOLVED: The file cannot be accessed concerrently. \n",
    "    Should open a new file handle\n",
    "    for each run. \n",
    "    \"\"\"\n",
    "    bw = pyBigWig.open(\"../Data/DNase/wgEncodeRegDnaseClusteredV3.bigwig\")\n",
    "    try:\n",
    "        return np.mean(bw.values(ch, start, end))\n",
    "    except RuntimeError:\n",
    "        return 0\n",
    "\n",
    "def apply_get_max_dnase(bed_df):\n",
    "    \"\"\"\n",
    "    Get max DNase fold enrichment over the whole\n",
    "    dataframe using pandas apply function\n",
    "    \"\"\"\n",
    "    test = bed_df.apply(lambda row: get_max_dnase(row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "    mean_shape = test.fillna(0)\n",
    "    \n",
    "    return mean_shape\n",
    "\n",
    "def get_max_phatscon(con_file, ch, start, end):\n",
    "    \"\"\"\n",
    "    Extract the maximum fold enrichment from Bigwig files\n",
    "    \n",
    "    Keep in mind this error:\n",
    "    \"An error occurred while fetching values!\"\n",
    "    \n",
    "    This error lead to incorrect results. \n",
    "    Will have to re-think way out latter\n",
    "    \n",
    "    SOLVED: The file cannot be accessed concerrently. \n",
    "    Should open a new file handle\n",
    "    for each run. \n",
    "    \"\"\"\n",
    "    bw = pyBigWig.open(con_file)\n",
    "    try:\n",
    "        return np.mean(bw.values(ch, start, end))\n",
    "    except RuntimeError:\n",
    "        return 0\n",
    "\n",
    "def apply_get_phatscon(bed_df, con_type=\"phastCons\"):\n",
    "    \"\"\"\n",
    "    Get max DNase fold enrichment over the whole\n",
    "    dataframe using pandas apply function\n",
    "    \"\"\"\n",
    "    con_file = \"../Data/phatsCos/hg19.100way.%s.bw\" % con_type\n",
    "    test = bed_df.apply(lambda row: get_max_phatscon(con_file, row[0], row[1], row[2]), axis=1)\n",
    "    \n",
    "    mean_shape = test.fillna(0)\n",
    "    \n",
    "    return mean_shape\n",
    "\n",
    "def get_contigmers_dict(congtigmer, kmer_name):\n",
    "    \"\"\"\n",
    "    Convert the forward and reverse kmers into a dictionary\n",
    "    for a quick look-up and scoring of sequences\n",
    "    \"\"\"\n",
    "    test = pd.read_table(congtigmer, header=None,index_col=0, usecols=[0,1,3])\n",
    "    test.columns = [[\"8-mers\", \"E-score\"]]\n",
    "    test.index.name = \"8-mers\"\n",
    "    combined = test.set_index(\"8-mers\").append(test.drop(\"8-mers\", 1))\n",
    "    combined_dict = combined.to_dict()[\"E-score\"]\n",
    "\n",
    "    return combined_dict, kmer_name\n",
    "\n",
    "def insensitive_glob(pattern):\n",
    "    \"\"\"\n",
    "    Borrowed from answer here: \n",
    "    http://stackoverflow.com/questions/8151300/ignore-case-in-glob-on-linux\n",
    "    \"\"\"\n",
    "    def either(c):\n",
    "        return '[%s%s]'%(c.lower(),c.upper()) if c.isalpha() else c\n",
    "    return glob.glob(''.join(map(either,pattern)))\n",
    "\n",
    "def get_contigmers(tf):\n",
    "    \n",
    "    contig_path = \"../Data/PBM_2016/All_Contig8mers/*/*%s*\" % tf.capitalize()\n",
    "    return insensitive_glob(contig_path)\n",
    "\n",
    "def get_peak_files(tf):\n",
    "    peak_path = \"%s/*%s*\" % (chipseq_path,tf.capitalize())\n",
    "    \n",
    "    return glob.glob(peak_path)\n",
    "    #return insensitive_glob(peak_path)\n",
    "\n",
    "def add_best8(max_list):\n",
    "    max_pos = max_list.index(max(max_list))\n",
    "    sum(maxi[max_pos-4:max_pos+4])\n",
    "    \n",
    "def get_bed_from_peaks(peak, width, downstream_distance):\n",
    "    \"\"\"\n",
    "    Given a ChIp-seq peak file, process the peaks to\n",
    "    a given length and extract the possitive and \n",
    "    negative set of a given size\n",
    "    \n",
    "    \"\"\"\n",
    "    #Read the narrow peak file into a pandas DataFrame\n",
    "    \n",
    "    peak_file = pd.read_table(peak, header=None)[[0,1,2]]\n",
    "    \n",
    "    #Lets widden the coordinates to 100bp centered around the center\n",
    "    mid = (peak_file[2] + peak_file[1])/2\n",
    "    peak_file[1] = (mid - width/2+0.5).apply(int)\n",
    "    peak_file[2]  = (mid + width/2+0.5).apply(int)\n",
    "    \n",
    "    #Extract the negative set located 500bp downstream\n",
    "    neg_bed = peak_file.copy(deep=True)\n",
    "    \n",
    "    neg_bed[1] = neg_bed[1]+downstream_distance\n",
    "    neg_bed[2] = neg_bed[2]+downstream_distance\n",
    "    \n",
    "    # Eliminate repeat masked regions from the bed file\n",
    "    peak_file = remove_repeats(peak_file) #.to_csv(pos_bed_out, index=None, header=None, sep=\"\\t\")\n",
    "    neg_bed = remove_repeats(neg_bed) #.to_csv(neg_bed_out, index=None, header=None, sep=\"\\t\")\n",
    "    \n",
    "    #hg = \"/home/kipkurui/Project/MAT_server/Data/hg19.fa\"\n",
    "    return peak_file, neg_bed\n",
    "\n",
    "    # uncomment this, if you need Fasta sequences\n",
    "    #pybedtools.BedTool.from_dataframe(peak_file).sequence(fi=hg,).save_seqs(negfa_out)\n",
    "\n",
    "def remove_repeats(dfs):\n",
    "    \"\"\"\n",
    "    Takes a bed file dataframe and eliminated bed\n",
    "    coordinates that fall within the repeat masked sections\n",
    "    \"\"\"\n",
    "    repeats = pd.read_table(\"../Data/repeat_sites.bed\", header=None)\n",
    "    repeats = pybedtools.BedTool.from_dataframe(repeats)\n",
    "    \n",
    "    a = pybedtools.BedTool.from_dataframe(dfs)\n",
    "    \n",
    "    test = a.subtract(repeats, A=True)\n",
    "    \n",
    "    return test.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PWM\n",
    "\n",
    "I wonder if I need this here for now? I may have to import these from a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rc_pwm(area_pwm, pwm_len):\n",
    "    \"\"\"\n",
    "    Takes as input the forward pwm and returns a reverse\n",
    "    complement of the motif\n",
    "    \"\"\"\n",
    "\n",
    "    rcareapwm = {}\n",
    "    rcareapwm[\"A\"] = []\n",
    "    rcareapwm[\"C\"] = []\n",
    "    rcareapwm[\"G\"] = []\n",
    "    rcareapwm[\"T\"] = []\n",
    "    rcareapwm[\"N\"] = []\n",
    "    for i in range(pwm_len):\n",
    "        rcareapwm[\"A\"].append(area_pwm[\"T\"][pwm_len - i - 1])\n",
    "        rcareapwm[\"C\"].append(area_pwm[\"G\"][pwm_len - i - 1])\n",
    "        rcareapwm[\"G\"].append(area_pwm[\"C\"][pwm_len - i - 1])\n",
    "        rcareapwm[\"T\"].append(area_pwm[\"A\"][pwm_len - i - 1])\n",
    "        rcareapwm[\"N\"].append(0.0)\n",
    "    return rcareapwm\n",
    "\n",
    "\n",
    "def get_motif(meme, motif=\"MOTIF\"):\n",
    "    \"\"\"\n",
    "    Extract a motif from meme file given a unique motif\n",
    "    name and create dictionary for sequence scoring\n",
    "\n",
    "    Default motif name is keyword MOTIF for single motif files. \n",
    "    \"\"\"\n",
    "\n",
    "    pwm_dictionary = {}\n",
    "    pwm_dictionary[\"A\"] = []\n",
    "    pwm_dictionary[\"C\"] = []\n",
    "    pwm_dictionary[\"G\"] = []\n",
    "    pwm_dictionary[\"T\"] = []\n",
    "    pwm_dictionary[\"N\"] = []\n",
    "    flag = 0\n",
    "    check = 0\n",
    "    with open(meme, \"r\") as f1:\n",
    "        for line in f1:\n",
    "            if str(motif) in line:\n",
    "                flag += 1\n",
    "            if \"letter-probability\" in line and flag == 1:\n",
    "                w = line.split(\" \")[5]\n",
    "                flag += 1\n",
    "                continue\n",
    "            if flag == 2 and int(check) < int(w):\n",
    "                if line == \"\\n\":\n",
    "                    continue\n",
    "                else:\n",
    "                    words = line.split()\n",
    "                    pwm_dictionary[\"A\"].append(float(words[0]))\n",
    "                    pwm_dictionary[\"C\"].append(float(words[1]))\n",
    "                    pwm_dictionary[\"G\"].append(float(words[2]))\n",
    "                    pwm_dictionary[\"T\"].append(float(words[3]))\n",
    "                    pwm_dictionary[\"N\"].append(0.0)\n",
    "                    check += 1\n",
    "        return pwm_dictionary\n",
    "\n",
    "    \n",
    "\n",
    "def maxoccupancyscore(pwm_dictionary, seq):\n",
    "    \"\"\"\n",
    "    Takes as input a PWM dictionary, and a sequences and\n",
    "    computes the sum occupancy score.\n",
    "    \"\"\"\n",
    "    if \"N\" in seq:\n",
    "        return 0\n",
    "    else:\n",
    "        # pwm_length = len(pwm_dictionary)\n",
    "        pwm_length = len(pwm_dictionary[\"A\"])\n",
    "        occupancy_list = []\n",
    "        pwm_dictionary_rc = rc_pwm(pwm_dictionary, pwm_length)\n",
    "        for i in range(len(seq) - 1):\n",
    "            occupancy = 1\n",
    "            occupancy_rc = 1\n",
    "            for j in range(pwm_length - 1):\n",
    "                if (j + i) >= len(seq):\n",
    "                    occupancy *= 0.25\n",
    "                    occupancy_rc *= 0.25\n",
    "                elif seq[j + i] not in [\"A\", \"C\", \"G\", \"T\"]:\n",
    "                    occupancy *= 0.25\n",
    "                    occupancy_rc *= 0.25\n",
    "                else:\n",
    "                    occupancy *= pwm_dictionary[seq[j + i]][j]\n",
    "                    occupancy_rc *= pwm_dictionary_rc[seq[j + i]][j]\n",
    "            occupancy_list.append(occupancy)\n",
    "            occupancy_list.append(occupancy_rc)\n",
    "        max_occupancy = max(occupancy_list)\n",
    "        return max_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BASE_DIR = \"/home/kipkurui/Dream_challenge/DreamChallenge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "import rpy2\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "def train_xgboost(dataframe, y, tf):\n",
    "    \"\"\"\n",
    "    Given a feature DF, train a model using the optimized parameters\n",
    "    \n",
    "    The parameters are chosen using cross validation\n",
    "    \"\"\"\n",
    "    xgdmat = xgb.DMatrix(dataframe, y) \n",
    "\n",
    "    our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':8, 'min_child_weight':1} \n",
    "\n",
    "    final_gb = xgb.train(our_params, xgdmat, num_boost_round = 3000)\n",
    "    \n",
    "    #save the model for future reference\n",
    "    #pickle.dump(final_gb, \"%s/annotations/%s/%s_xgboost_pick.dat\" % (BASE_DIR, tfs, tfs))\n",
    "    #joblib.dump(final_gb, \"%s/annotations/%s/%s_xgboost.dat\" % (BASE_DIR, tfs, tfs))\n",
    "    \n",
    "    #Creat a feature importance plot\n",
    "    plot_feature_importance(final_gb, \"%s_features.png\" % tf)\n",
    "    \n",
    "    return final_gb\n",
    "\n",
    "\n",
    "def plot_feature_importance(xgb_model, fig_out):\n",
    "    sns.set(font_scale = 1.5)\n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1 )  # create figure & 1 axis\n",
    "    xgb.plot_importance(xgb_model, ax=ax)\n",
    "    #ax.plot([0,1,2], [10,20,3])\n",
    "    fig.savefig(fig_out, bbox_inches='tight')   # save the figure to file\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "def get_auc(y_test, y_pred, lab=1):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=lab)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def scikitlearn_calc_auPRC(y_true, y_score):\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "def calc_auPRC(y_true, y_score):\n",
    "    \"\"\"Calculate auPRC using the R package \n",
    "    \n",
    "    From DREAM challenge organizers\n",
    "\n",
    "    \"\"\"\n",
    "    ro.globalenv['pred'] = y_score\n",
    "    ro.globalenv['labels'] = y_true\n",
    "    return ro.r('library(PRROC); pr.curve(scores.class0=pred, weights.class0=labels)$auc.davis.goadrich')[0]\n",
    "\n",
    "def recall_at_fdr(y_true, y_score, fdr_cutoff=0.05):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "    fdr = 1- precision\n",
    "    cutoff_index = next(i for i, x in enumerate(fdr) if x <= fdr_cutoff)\n",
    "    return recall[cutoff_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process the peak data into negative and positive sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_combined_bed(peak):\n",
    "    \"\"\"\n",
    "    Extract and combine the positive and negative\n",
    "    sequences into a single DataFrame\n",
    "    \"\"\"\n",
    "    peak_file, neg_bed = get_bed_from_peaks(peak, 100, 500)\n",
    "\n",
    "    trim_to = min(len(peak_file), len(neg_bed))\n",
    "    trim_to = trim_to/2\n",
    "    pos_bed = peak_file.head(trim_to)\n",
    "    pos_bed.sort_values(by=[\"chrom\", \"start\",\"end\"], inplace=True)\n",
    "    neg_bed = neg_bed.head(trim_to)\n",
    "    neg_bed.sort_values(by=[\"chrom\", \"start\",\"end\"], inplace=True)\n",
    "\n",
    "    combined_bed = pos_bed.append(neg_bed, ignore_index=True)\n",
    "    \n",
    "    return combined_bed, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll drop this for now and only bring it up when I want to compare\n",
    "def get_motif_details(tfs):\n",
    "    \"\"\"\n",
    "    Given a TF name, create a three pwm dictionaries for scoring. \n",
    "    \"\"\"\n",
    "    \n",
    "    tf_l = tfs.capitalize()\n",
    "\n",
    "    pwm_motif = \"../Motifs/%s.meme\" % tfs\n",
    "\n",
    "    tom_score = \"../Motifs/%s.tomtom\" % tfs\n",
    "    \n",
    "    mots = !cut -f1 {tom_score}\n",
    "    mot = mots[1]\n",
    "    pwm_dictionary = get_motif(pwm_motif, motif=mot)\n",
    "    \n",
    "    return pwm_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create kmer dictionaries for the features of interest\n",
    "We have two option here:\n",
    "1. Backround noise scalled in a simiklar maner to sticky k-mers \n",
    "1. Preferred k-mers max normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test = pd.read_table(\"rewighed_hg_dn_scores\")\n",
    "# minmax_df = pd.read_table(minmax, header=None)\n",
    "# test[\"E-score\"] = minmax_df[1]\n",
    "# test.to_csv(\"dn_hg_max_normalized.txt\", sep=\"\\t\", header=True, index=False)\n",
    "# dn_hg_dict, kmer_name = get_kmer_dict_rev(\"rewighed_hg_dn_scores\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Where best can I put these files?\n",
    "\n",
    "dn_hg_dict, kmer_name = get_kmer_dict_rev(\"dn_hg_max_normalized.txt\", \"test\")\n",
    "\n",
    "dn_hg_dict2, kmer_name = get_kmer_dict_rev(\"hg_dn_backround_noise_minmax.txt\", \"test\")\n",
    "\n",
    "# kmerscore = \"hg_dn_backround_noise_minmax.txt\"\n",
    "# test = pd.read_table(kmerscore, header=None, index_col=0)\n",
    "# dn_hg_dict2 = test[1].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Score the sequences of interest\n",
    "\n",
    "#### a) K_mer score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kmer_score(combined_bed, score_fun, score_dict):\n",
    "    \"\"\"\n",
    "    Given a bed file, score the sequences using \n",
    "    \"\"\"\n",
    "    global pwm_dictionary\n",
    "    global score_function\n",
    "    \n",
    "    pwm_dictionary =score_dict\n",
    "    score_function=score_fun\n",
    "    \n",
    "    return score_from_genome(combined_bed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all data prepapration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distance_to_tss(bed):\n",
    "    \"\"\"\n",
    "    Given a bed file, calculate the distance from the \n",
    "    midpoint to the nearest TSS\n",
    "    \n",
    "    \"\"\"\n",
    "    tss = pd.read_table(\"../Data/Tss_hg19_refseq\", header=None)\n",
    "    tss[2] = tss[1] + 1\n",
    "    tss[1] = tss[1] - 1\n",
    "    tss = tss.sort_values(by=[0,1,2], kind=\"mergesort\")\n",
    "    \n",
    "    bed = bed.sort_values(by=[\"chrom\", \"start\",\"end\"], kind=\"mergesort\")\n",
    "    \n",
    "    tss_obj = pybedtools.BedTool.from_dataframe(tss)\n",
    "    \n",
    "    bed_obj = pybedtools.BedTool.from_dataframe(bed)\n",
    "    \n",
    "    bed_closest = bed_obj.closest(tss_obj)\n",
    "    bed_closest = bed_obj.closest(tss_obj, d=True,k=1,t='first')\n",
    "    bed_closest_df = bed_closest.to_dataframe()\n",
    "    \n",
    "    return bed_closest_df[\"thickStart\"]\n",
    "    \n",
    "def get_hits_df(double_deal, combined_bed):\n",
    "    \"\"\"\n",
    "    Given BED DataFrame and coordinate of the hit site\n",
    "    Create a DF with shape hit coordinates\n",
    "    \n",
    "    \"\"\"\n",
    "    shape_hits = combined_bed.copy()\n",
    "    shape_hits['start'] = combined_bed['start'] + double_deal[1].apply(int)\n",
    "    shape_hits['end'] = shape_hits['start'] + 8\n",
    "    \n",
    "    return shape_hits\n",
    "\n",
    "def get_shape_names(shape):\n",
    "    \"\"\"\n",
    "    Label each of the shape features\n",
    "    \"\"\"\n",
    "    name_list = []\n",
    "    for i in range(8):\n",
    "        name_list.append(\"%s_%i\" % (shape,i))\n",
    "        \n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_df(tf, pos):\n",
    "    \"\"\"\n",
    "    Given a TF and the position of the peak file of interest\n",
    "    Creat a DataFrame with all the coordinates\n",
    "    \n",
    "    This is the main Feature Vector\n",
    "    \"\"\"\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    ## Calculate all the necessary features\n",
    "    #E_score_combined = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "    feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "    feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train a model using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ../Data/repeat_sites.bed does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9f12fa725fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ap2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-998e25ad047f>\u001b[0m in \u001b[0;36mget_feature_df\u001b[1;34m(tf, pos)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpeak_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_peak_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcombined_bed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_combined_bed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeak_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mE_score_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_contigmers_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_contigmers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c118ebc7f0b2>\u001b[0m in \u001b[0;36mget_combined_bed\u001b[1;34m(peak)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpeak_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_bed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bed_from_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeak\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrim_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeak_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_bed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2168a18bf158>\u001b[0m in \u001b[0;36mget_bed_from_peaks\u001b[1;34m(peak, width, downstream_distance)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;31m# Eliminate repeat masked regions from the bed file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m     \u001b[0mpeak_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_repeats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeak_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#.to_csv(pos_bed_out, index=None, header=None, sep=\"\\t\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m     \u001b[0mneg_bed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_repeats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_bed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#.to_csv(neg_bed_out, index=None, header=None, sep=\"\\t\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2168a18bf158>\u001b[0m in \u001b[0;36mremove_repeats\u001b[1;34m(dfs)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[0mcoordinates\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mfall\u001b[0m \u001b[0mwithin\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrepeat\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m--> 428\u001b[1;33m     \u001b[0mrepeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../Data/repeat_sites.bed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m     \u001b[0mrepeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpybedtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBedTool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File ../Data/repeat_sites.bed does not exist"
     ]
    }
   ],
   "source": [
    "feature_frame, trim_to = get_feature_df(\"Ap2\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-02fa1872be73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtf_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tf_name\\tAll\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtf_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s\\t\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Ap2\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_list' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    \n",
    "    tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    for j in feat_list:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in {\"Ap2\"}:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_best(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_best(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in feat_list:\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(feature_frame_p.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pbm_chip = []\n",
    "pbmchip2name = {}\n",
    "with open(\"/home/kipkurui/Project/Motif_Assessment/PAPER_Assessment_Data/NAR_Paper/Data/Pbm_Chip_details.txt\") as pbmnchip:\n",
    "    for line in pbmnchip:\n",
    "        if line.startswith('Tf_id'):\n",
    "            continue\n",
    "        else:\n",
    "            pbm_chip.append(line.split()[0])\n",
    "            pbmchip2name[line.split()[1]] = line.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sticky_tfs = pd.read_table(\"/home/kipkurui/Project/Others_work/Bayesian_PBM_Analysis/Bayesian_PBM_Analysis/anova_example/input/names.txt\", header=None)\n",
    "tf_list = []\n",
    "for tf in sticky_tfs[0]:\n",
    "    chip_list = glob.glob(\"/home/kipkurui/Project/MARS/Data/ChIP-seq/Derived/Posneg/%s/*\" % tf.capitalize())\n",
    "    if len(chip_list) > 0:\n",
    "        tf_list.append(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of Tfs available in PBM and ChIP with more than two peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taf1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_pbm = pd.read_table(\"/home/kipkurui/Project/Motif_Assessment/PAPER_Assessment_Data/NAR_Paper/Data/Pbm_Chip_details.txt\")\n",
    "\n",
    "in_both = tf_pbm[(tf_pbm[\"Chip_name\"] >0) == (tf_pbm[\"Pbm_name\"] >0)]\n",
    "chip_name = tf_pbm[(tf_pbm[\"Chip_name\"] >0)][\"Chip_name\"]\n",
    "chip_name = chip_name.sort_values()\n",
    "\n",
    "in_both_new = []\n",
    "for tf in chip_name:\n",
    "    if (len(get_contigmers(tf)) > 0) & (len(get_peak_files(tf)) > 1):\n",
    "        #print get_contigmers(tf)\n",
    "        in_both_new.append(tf)\n",
    "#Remove Taf1 -- Wrongly picked above\n",
    "in_both_new.pop(in_both_new.index(\"Taf1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ap2',\n",
       " 'Arid3a',\n",
       " 'Egr1',\n",
       " 'Elk1',\n",
       " 'Elk4',\n",
       " 'Ets1',\n",
       " 'Gabp',\n",
       " 'Gata3',\n",
       " 'Gr',\n",
       " 'Hnf4a',\n",
       " 'Irf3',\n",
       " 'Jund',\n",
       " 'Mafk',\n",
       " 'Max',\n",
       " 'Pou2f2',\n",
       " 'Rxra',\n",
       " 'Sp1',\n",
       " 'Srf',\n",
       " 'Tbp',\n",
       " 'Tcf7l2']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_both_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_both_new2 = ['Ap2',\n",
    " 'Arid3a',\n",
    " 'Egr1',\n",
    " 'Elk1',\n",
    " 'Elk4',\n",
    " 'Ets1',\n",
    " 'Gabp',\n",
    " 'Gata3',\n",
    " 'Gr',\n",
    " 'Hnf4a',\n",
    " 'Irf3',\n",
    " 'Jund',\n",
    " 'Mafk',\n",
    " 'Max',\n",
    " 'Pou2f2',\n",
    " 'Rxra',\n",
    " 'Sp1',\n",
    " 'Srf',\n",
    " 'Tbp',\n",
    " 'Tcf7l2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Same as above, but older\n",
    "\n",
    "Kept for reference purposes only, unless we find some use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to_dict = in_both.set_index(\"Chip_name\").drop(\"Tf_id\", 1)\n",
    "# pbm2chip = to_dict.to_dict()['Pbm_name']\n",
    "\n",
    "# my_new_list = []\n",
    "# for tf in pbm2chip:\n",
    "#     chip_list = glob.glob(\"/home/kipkurui/Project/MARS/Data/ChIP-seq/Downloaded/*%s*\" % pbm2chip[tf].capitalize())\n",
    "#     if len(chip_list) > 1:\n",
    "#         my_new_list.append(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my_new_list = ['Srf','Hnf4a',\n",
    "#  'Arid3a',\n",
    "#  'Tbp',\n",
    "#  'Elk1',\n",
    "#  'Elk4',\n",
    "#  'Gata3',\n",
    "#  'Irf3',\n",
    "#   'Tcf7l2',\n",
    "#  'Pou2f2',\n",
    "#  'Egr1',\n",
    "#  'Rxra',\n",
    "#  'Ets1',\n",
    "#  'Mafk',\n",
    "#  'Max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = ['max_kmer_score',\"phatsCons\",'dn_hg_score','dnase', \"tss_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_list = ['kmer_score',\n",
    " 'max_kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos',\n",
    " 'dn_hg_score',\n",
    " 'dn_hg_score2',\n",
    " 'dnase', \"tss_dist\", \"phyloP100way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_list = [\n",
    " 'max_kmer_score',\"phatsCons\",\n",
    " 'dn_hg_score2',\n",
    " 'dnase', \"tss_dist\", \"phyloP100way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for tf in in_both_new:\n",
    "#     print tf\n",
    "#     print pbmchip2name[tf]\n",
    "#     get_motif_details(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overal_list = []\n",
    "for feat in feat_list:\n",
    "    feats = feat_list[:]\n",
    "    feats.pop(feats.index(feat))\n",
    "    overal_list.append(feats[:])\n",
    "for feat1 in feat_list:\n",
    "    new_l = [feat1]\n",
    "    for feat in feat_list:\n",
    "        if not feat in new_l:\n",
    "            new_l.append(feat)\n",
    "            new_l.sort()\n",
    "            add_in = new_l[:]\n",
    "            if add_in not in overal_list:\n",
    "                overal_list.append(add_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"feature_details_importance\", \"w\") as feats:   \n",
    "    for j, yu in enumerate(overal_list):\n",
    "        #print feat_list[j]+\"_\"+str(j)\n",
    "        feats.write(\"AUC_%i\\t %s\\n\" % (j, '|'.join(yu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_feats = list(feature_frame2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pop_this(feat):\n",
    "    try:\n",
    "        all_feats.pop(all_feats.index(feat))\n",
    "    except ValueError:\n",
    "        try:\n",
    "            for i in range(8):\n",
    "                all_feats.pop(all_feats.index(feat+\"_%i\" % i))\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def pop_this(remove):\n",
    "#     for feat in list(feature_frame2.columns):\n",
    "#         if remove in feat:\n",
    "#             all_feats.pop(all_feats.index(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pop_this(\"dnase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_frame2, trim_to = get_feature_df(tf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_best6(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    ## Calculate all the necessary features\n",
    "    #E_score_combined = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "#     feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    #feature_frame[\"dnase\"] = apply_get_max_dnase(combined_bed)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "#     feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "#     feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "#     feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "#     feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "#     feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "#     for shape in \"ProT MGW HelT Roll\".split():\n",
    "#         #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "#         feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "#         feature_fr.columns = get_shape_names(shape)\n",
    "#         feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by eliminating one, sequentially\n",
    "\n",
    "The shape features will have to be eliminated together as a group.This is an attempt to be clear on the contribution to teh accuracy by each of the features. \n",
    "\n",
    "Next, I need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_tfs = [\"Gr\",\"Tbp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    \n",
    "    #tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_best(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_best(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in feat_list:\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance by recursive addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_all.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\t\")\n",
    "    feat_list = ['kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos','dn_hg_score',\n",
    " 'dn_hg_score2',\"tss_dist\", \"phyloP100way\"]\n",
    "    for j in feat_list:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs: #in_both_new:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "#         #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_df(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_df(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "#         #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        feat_list = ['kmer_score',\"phatsCons\",\n",
    " 'Roll', 'ProT', 'MGW', 'HelT',\n",
    " 'max_kmer_score_pos','dn_hg_score',\n",
    " 'dn_hg_score2',\"tss_dist\", \"phyloP100way\"]\n",
    "        loop_this = feat_list[:]\n",
    "        for i,j in enumerate(loop_this):\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            feat_list = ['kmer_score',\"phatsCons\",\n",
    "             'Roll', 'ProT', 'MGW', 'HelT',\n",
    "             'max_kmer_score_pos','dn_hg_score',\n",
    "             'dn_hg_score2',\"tss_dist\", \"phyloP100way\"]\n",
    "            #print i,j\n",
    "            feat_list.pop(i)\n",
    "\n",
    "            for i in feat_list:\n",
    "                pop_this(i)\n",
    "#             print all_feats\n",
    "#         for feats in feat_list:\n",
    "#             all_feats = list(feature_frame.columns)\n",
    "#             pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pybedtools.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we cal confidently deduce that the most informative feature as dnase and tss...however, for other features, we lose information on the quality of the model since k-mer scores are will not be confidently measured. Therefore, we eliminate the poorly performing features and then introduce. \n",
    "\n",
    "## Contribution of the DNA shape to the baseline model\n",
    "\n",
    "Here, we will have a complete feature with:\n",
    "* The max k-mer score\n",
    "* The DNase score\n",
    "* The Each of the shape features\n",
    "\n",
    "So the Idea is to start with a complete model, then one with a  variation of each of the shape features. \n",
    "\n",
    "The difficulty with these is that the model does not consider the order of the features, rather, it starts with the first ones and moves along with the rest. So, generally, the feature presented first seems to have high contribution to the tree decisions. \n",
    "\n",
    "Here we want to observe the contribution, rather than how much a dip adding the feature causes. Then decide on the contribution of each of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_df_shape(tf, pos):   \n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "#     feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    #feature_frame[\"dnase\"] = apply_get_max_dnase(combined_bed)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "#     feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "#     feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "#     feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "#     feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "#     feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "#     pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "#     neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "#     pos_neg_tss = pos_tss.append(neg_tss)\n",
    "#     pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "#     feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_shape3.txt\", \"a\") as tf_scores:\n",
    "    tf_scores.write(\"Tf_name\\tAll\\tNone\\t\")\n",
    "    for j in [ 'Roll', 'ProT', 'MGW', 'HelT']:\n",
    "        tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs:#in_both_new[17:]:\n",
    "        shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_df_shape(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_df_shape(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for i in shapes:\n",
    "            pop_this(i)\n",
    "        my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "        testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "        y_pred = my_model.predict(testdmat)\n",
    "        tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        for i,j in enumerate([ 'Roll', 'ProT', 'MGW', 'HelT']):\n",
    "            all_feats = list(feature_frame.columns)\n",
    "            shapes = [ 'Roll', 'ProT', 'MGW', 'HelT']\n",
    "            #print i,j\n",
    "            shapes.pop(i)\n",
    "\n",
    "            for i in shapes:\n",
    "                pop_this(i)\n",
    "    \n",
    "#         for feats in feat_list:\n",
    "#             all_feats = list(feature_frame.columns)\n",
    "#             pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "\n",
    "            testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the effect of the preferred and noise k-mer scores as an additional feature\n",
    "\n",
    "Question here is to determine if it does contribute to the predictive ability of the model. Here we can extract the information from the feature contribution based on how much loss it causes. \n",
    "\n",
    "Here, we also want to use the baseline model comprosing of the DNase and kmer scores...that is after determining the best scoring function we just settle on that for any subsequent computation. The level of correlation of the various features is also informative in terms of how much more value they can add to the quality of the model. \n",
    "\n",
    "With this, the best option, is to test the performance of the baseline with k-mer model and with Dnase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_features = [[\"dnase\", \"max_kmer_score\",\"dn_hg_score\",\"dn_hg_score2\"],[\"dnase\", \"max_kmer_score\"],[\"dnase\", \"max_kmer_score\",\"dn_hg_score2\"], [\"dnase\", \"max_kmer_score\",\"dn_hg_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_noise(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "#     feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    #feature_frame[\"dnase\"] = apply_get_max_dnase(combined_bed)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "#     feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "#     feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "#     feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "#     pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "#     neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "#     pos_neg_tss = pos_tss.append(neg_tss)\n",
    "#     pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "#     feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "#     for shape in \"ProT MGW HelT Roll\".split():\n",
    "#         #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "#         feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "#         feature_fr.columns = get_shape_names(shape)\n",
    "#         feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sp1', 'Srf', 'Tbp', 'Tcf7l2']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_both_new[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_noise.txt\", \"a\") as tf_scores:\n",
    "    #tf_scores.write(\"Tf_name\\tAll\\tNone\\tNoise\\tPreferred\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in repeat_tfs:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_noise(tf, 0)\n",
    "        #for pos in range(1,len(get_peak_files(tf)))\n",
    "        feature_frame_p,trim_to_p =  get_feature_noise(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "#         my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "#         testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "#         y_pred = my_model.predict(testdmat)\n",
    "#         tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in noise_features:\n",
    "            #all_feats = list(feature_frame.columns)\n",
    "            #pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test how well the models can be generalizable\n",
    "\n",
    "To do this, I need to identify those TFS that have data in more than three cell lines, then use that infromation to test how a model trained in a rottatting manner can be used top predict binding in teh other cell lines and, what is the accuracy. Although, in a way, our current implementation where we train in one and test in another is okay, we need to check and see if there exists flactuations in performance depending on the training cell line. \n",
    "\n",
    "Given a TF with more than one cell line, we get the name and then test prediction ability of a model from one cell line in predicting performance in another cell line.\n",
    "* Start with single cell line, and if we do observe some irregularities, then --\n",
    "* Create a  model from each of the cell lines testing the perfomance in the other cell lines. \n",
    "* Determine how well we can generalize our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabp\n",
      "Gata3\n",
      "Gr\n",
      "Jund\n",
      "Mafk\n",
      "Max\n",
      "Sp1\n",
      "Srf\n",
      "Tbp\n",
      "Tcf7l2\n"
     ]
    }
   ],
   "source": [
    "over_3 = []\n",
    "for tf in in_both_new:\n",
    "    #print tf\n",
    "    peak_files = get_peak_files(tf)\n",
    "    if (len(peak_files) > 3) & (len(peak_files) < 10):\n",
    "        over_3.append(tf)\n",
    "        print tf\n",
    "    #print get_celltype(peak_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_celltype(peak_files):\n",
    "    cell_types = []\n",
    "    for i in range(len(peak_files)):\n",
    "        cell_types.append(peak_files[i].split(\"/\")[-1].split(\"Tfbs\")[-1].split(\"UniPk\")[0])\n",
    "    return cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_cell_type(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "#     feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    #feature_frame[\"dnase\"] = apply_get_max_dnase(combined_bed)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "#     feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "    feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "    pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "    neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "    pos_neg_tss = pos_tss.append(neg_tss)\n",
    "    pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "    feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "    for shape in \"ProT MGW HelT Roll\".split():\n",
    "        #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "        feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "        feature_fr.columns = get_shape_names(shape)\n",
    "        feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_cell_type_specificity_1.txt\", \"a\") as tf_scores:\n",
    "    #tf_scores.write(\"Tf_name\\tAll\\tNone\\tNoise\\tPreferred\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in reapeat_tfs:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_cell_type(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        my_model = train_xgboost(feature_frame, y_train, tf)\n",
    "        for pos in range(0,len(get_peak_files(tf))-1):\n",
    "            feature_frame_p,trim_to_p =  get_feature_cell_type(tf, pos)\n",
    "\n",
    "            y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "\n",
    "            all_feats = list(feature_frame.columns)\n",
    "\n",
    "            testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(get_peak_files(tf))):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gabp', 'Gata3', 'Gr', 'Jund', 'Mafk', 'Max', 'Sp1', 'Srf', 'Tbp', 'Tcf7l2']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the different training cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over_3 = ['Gabp', 'Gata3', 'Jund', 'Mafk', 'Max', 'Sp1', 'Srf', 'Tbp', 'Tcf7l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pybedtools.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "over_3 = ['Max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_cell_type_specificity_recursive.txt\", \"a\") as tf_scores:\n",
    "    #tf_scores.write(\"Tf_name\\tAll\\tNone\\tNoise\\tPreferred\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in over_3:\n",
    "        tf_scores.write(\"\\n%s\\n\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "        for train in range(len(get_peak_files(tf))):\n",
    "            pybedtools.cleanup()\n",
    "            tf_scores.write(\"%s\\t\" % get_celltype(get_peak_files(tf))[train])\n",
    "            feature_frame, trim_to = get_feature_cell_type(tf, train)\n",
    "            y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "            my_model = train_xgboost(feature_frame, y_train, tf)\n",
    "            for pos in range(len(get_peak_files(tf))):\n",
    "                feature_frame_p,trim_to_p =  get_feature_cell_type(tf, pos)\n",
    "\n",
    "                y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "\n",
    "                all_feats = list(feature_frame.columns)\n",
    "\n",
    "                testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "\n",
    "                y_pred = my_model.predict(testdmat)\n",
    "\n",
    "                tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for conservation data contribution\n",
    "\n",
    "Using the same idea, we need to test the various forms of acquiring the consevation scores and their effect on the perfomance of the model. Here are to test the following:\n",
    "* Phastcons hit\n",
    "* phastcons whole site\n",
    "* Phylo hit\n",
    "* phylo whole site\n",
    "\n",
    "With each of these, we use the baseline model already defined and tested. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_conservation(tf, pos):\n",
    "    peak_files = get_peak_files(tf)\n",
    "\n",
    "    combined_bed, trim_to = get_combined_bed(peak_files[pos])\n",
    "\n",
    "    E_score_dict, kmer_name = get_contigmers_dict(get_contigmers(tf)[0],\"test\")\n",
    "\n",
    "    feature_frame = pd.DataFrame()\n",
    "#     feature_frame[\"kmer_score\"] = get_kmer_score(combined_bed, energy_score_kmer, E_score_dict)\n",
    "    #feature_frame[\"dnase\"] = apply_get_max_dnase(combined_bed)\n",
    "    feature_frame [\"max_kmer_score\"] = get_kmer_score(combined_bed, max_score_kmer, E_score_dict)\n",
    "    test_score = get_kmer_score(combined_bed, max_score_kmer_pos, E_score_dict)\n",
    "    double_deal = test_score.apply(pd.Series)\n",
    "#     feature_frame [\"max_kmer_score_pos\"] = double_deal[0]\n",
    "    hits_df = get_hits_df(double_deal, combined_bed)\n",
    "    feature_frame[\"dnase\"] = apply_get_max_dnase(hits_df)\n",
    "    feature_frame[\"phatsCons\"] = apply_get_phatscon(hits_df)\n",
    "    feature_frame[\"phyloP100way\"] = apply_get_phatscon(hits_df, \"phyloP100way\")\n",
    "    \n",
    "    feature_frame[\"phatsCons_whole\"] = apply_get_phatscon(combined_bed)\n",
    "    feature_frame[\"phyloP100way_whole\"] = apply_get_phatscon(combined_bed, \"phyloP100way\")\n",
    "    \n",
    "#     feature_frame[\"dn_hg_score\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict)\n",
    "#     feature_frame[\"dn_hg_score2\"] = get_kmer_score(combined_bed, max_score_kmer, dn_hg_dict2)\n",
    "#     feature_frame[\"pwm_score\"] = get_kmer_score(combined_bed, energyscore, get_motif_details(tf))\n",
    "    feature_frame.reset_index(drop=True, inplace=True)\n",
    "#     pos_tss = get_distance_to_tss(hits_df.head(trim_to))\n",
    "#     neg_tss = get_distance_to_tss(hits_df.tail(trim_to))\n",
    "#     pos_neg_tss = pos_tss.append(neg_tss)\n",
    "#     pos_neg_tss.reset_index(drop=True, inplace=True) \n",
    "#     feature_frame[\"tss_dist\"] = pos_neg_tss\n",
    "#     for shape in \"ProT MGW HelT Roll\".split():\n",
    "#         #feature_frame[\"%s_shape\" % shape] = apply_get_shape(hits_df, shape)\n",
    "#         feature_fr = apply_get_full_shape(hits_df).apply(pd.Series)\n",
    "#         feature_fr.columns = get_shape_names(shape)\n",
    "#         feature_frame = feature_frame.T.append(feature_fr.T).T\n",
    "    return feature_frame, trim_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conservation_features = [[\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                  [\"dnase\", \"max_kmer_score\"],\n",
    "                  [\"dnase\", \"max_kmer_score\",\"phyloP100way\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                  [\"dnase\", \"max_kmer_score\",\"phatsCons\", \"phatsCons_whole\",\"phyloP100way_whole\"],\n",
    "                 [\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\",\"phyloP100way_whole\"],\n",
    "                 [\"dnase\", \"max_kmer_score\",\"phatsCons\",\"phyloP100way\", \"phatsCons_whole\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbp\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_feature_importance_recursive_conservation.txt\", \"a\") as tf_scores:\n",
    "    #tf_scores.write(\"Tf_name\\tAll\\tNone\\tPhats_hit\\tPhylo_hit\\tPhats_wh\\tPhylo_wh\\t\")\n",
    "    #for j in feat_list:\n",
    "        #tf_scores.write(\"%s\\t\" % j)\n",
    "    for tf in reapeat_tfs:\n",
    "        tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "        #tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "        print tf\n",
    "\n",
    "        feature_frame, trim_to = get_feature_conservation(tf, 0)\n",
    "        feature_frame_p,trim_to_p =  get_feature_conservation(tf, -1)\n",
    "        y_train = np.concatenate((np.ones(trim_to), np.zeros(trim_to)), axis=0)\n",
    "        y_test = np.concatenate((np.ones(trim_to_p), np.zeros(trim_to_p)), axis=0)\n",
    "        \n",
    "        all_feats = list(feature_frame.columns)\n",
    "        \n",
    "        #All\n",
    "#         my_model = train_xgboost(feature_frame[all_feats], y_train, tf)\n",
    "#         testdmat = xgb.DMatrix(feature_frame_p[all_feats], y_test)\n",
    "#         y_pred = my_model.predict(testdmat)\n",
    "#         tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))\n",
    "        \n",
    "        for feats in conservation_features:\n",
    "            #all_feats = list(feature_frame.columns)\n",
    "            #pop_this(feats)\n",
    "            my_model = train_xgboost(feature_frame[feats], y_train, tf)\n",
    "            \n",
    "            testdmat = xgb.DMatrix(feature_frame_p[feats], y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t\" % (roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly compare the performance of the k-mer and the PWM models both derived from PBM data\n",
    "\n",
    "Here, the focus is to test the best scoring function for k-mers and the PWM derived from the same data. The intention is to determine if there exists any performance difference. \n",
    "\n",
    "For the pure k-mers, I had previously tested an option of scoring using k-mer above a given threshold. The benefit of this is that it will not be confounded by the poorly scoring k-mers. However, for a given sequence, teh number of k-mers above the trheshold will shift the scores in their favour, though it can be argues that this will still help pick up sequences with high scoring k-mers.\n",
    "\n",
    "The initial testing of this did not reveal this benefit...but it will not hurt to have a more comprehensive test, as well as for the thresholds (common ones are: 0.25 or 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ap2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kipkurui/anaconda2/envs/dream_challenge/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC 0.977606933355\n",
      "Arid3a\n",
      "AUPRC 0.880469079034\n",
      "Egr1\n",
      "AUPRC 0.910383578774\n",
      "Elk1\n",
      "AUPRC 0.97223757191\n",
      "Elk4\n",
      "AUPRC 0.960571050507\n",
      "Ets1\n",
      "AUPRC 0.943579325179\n",
      "Gabp\n",
      "AUPRC 0.952161968975\n",
      "Gata3\n",
      "AUPRC 0.907285569572\n",
      "Gr\n",
      "AUPRC 0.797471857658\n",
      "Hnf4a\n",
      "AUPRC 0.979244390734\n",
      "Irf3\n",
      "AUPRC 0.93453141081\n",
      "Jund\n",
      "AUPRC 0.911029543485\n",
      "Mafk\n",
      "AUPRC 0.963480840785\n",
      "Max\n",
      "AUPRC 0.928093808582\n",
      "Pou2f2\n",
      "AUPRC 0.945298583355\n",
      "Rxra\n",
      "AUPRC 0.711409542972\n",
      "Sp1\n",
      "AUPRC 0.908936667799\n",
      "Srf\n",
      "AUPRC 0.964137669576\n",
      "Tbp\n",
      "AUPRC 0.681431935356\n",
      "Tcf7l2\n",
      "AUPRC 0.863327983539\n"
     ]
    }
   ],
   "source": [
    "with open(\"TF_scores_best_shape_everything.txt\", \"a\") as tf_scores:\n",
    "    with open(\"TF_feats_best_shape_everything.txt\", \"a\") as tf_feats:\n",
    "        \n",
    "        tf_scores.write(\"Tf_name\\tAUC\\tAUPRC\\t\")\n",
    "#         for i in feat_list:\n",
    "#             tf_scores.write(i+\"\\t\")\n",
    "#             tf_feats.write(i+\"\\t\")\n",
    "        for tf in in_both_new:\n",
    "            tf_scores.write(\"\\n%s\\t\" % tf)\n",
    "            tf_feats.write(\"\\n%s\\t\" % tf)\n",
    "            print tf\n",
    "\n",
    "            feature_frame, trim_to = get_feature_df(tf, 0)\n",
    "            #feature_frame = shuffle_df_columns(feature_frame)\n",
    "            neg_size = trim_to\n",
    "            pos_size = trim_to\n",
    "            y_train = np.concatenate((np.ones(pos_size), np.zeros(neg_size)), axis=0)\n",
    "\n",
    "            my_model = train_xgboost(feature_frame, y_train, tf)\n",
    "\n",
    "            feature_frame_p,trim_to_p =  get_feature_df(tf, -1)\n",
    "            \n",
    "            #shuffling the df columns to test feature importance\n",
    "            #feature_frame_p = shuffle_df_columns(feature_frame_p)\n",
    "\n",
    "\n",
    "            neg_size = trim_to_p #len(pos_bed_p)\n",
    "            pos_size = trim_to_p #len(neg_bed_p)\n",
    "\n",
    "            y_test = np.concatenate((np.ones(pos_size), np.zeros(neg_size)), axis=0)\n",
    "\n",
    "            testdmat = xgb.DMatrix(feature_frame_p, y_test)\n",
    "\n",
    "            y_pred = my_model.predict(testdmat)\n",
    "\n",
    "            tf_scores.write(\"%s\\t%s\\t\" % (roc_auc_score(y_test, y_pred),calc_auPRC(y_test, y_pred)))\n",
    "\n",
    "            #print calc_auPRC(y_test, y_pred)\n",
    "            print \"AUPRC\", roc_auc_score(y_test, y_pred)\n",
    "#             importances = my_model.get_fscore()\n",
    "#             for feat in feat_list:\n",
    "#                 pwm_score = feature_frame_p[feat]\n",
    "#                 pwm_score = np.array(pwm_score)\n",
    "#                 tf_scores.write(\"%s\\t\" % roc_auc_score(y_test, pwm_score))\n",
    "#                 tf_feats.write(\"%s\\t\" % importances[feat])\n",
    "                \n",
    "            \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pybedtools.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_df_columns(df):\n",
    "    \"This really doesn't add much value\"\n",
    "    import random\n",
    "    asd = list(df.columns)\n",
    "    random.seed(12456)\n",
    "    random.shuffle(asd)\n",
    "    return df[asd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.967028447896\n",
    "Arid3a\n",
    "0.852579262049\n",
    "Egr1\n",
    "0.911651140092\n",
    "Elk1\n",
    "0.97114564576\n",
    "Elk4\n",
    "0.962128973571\n",
    "Ets1\n",
    "0.932960986153\n",
    "Gabp\n",
    "0.947173738305\n",
    "Gata3\n",
    "0.887761995812\n",
    "Gr\n",
    "0.743983361148\n",
    "Hnf4a\n",
    "0.965655318165\n",
    "Irf3\n",
    "0.927597905978\n",
    "Jund\n",
    "0.91214940445\n",
    "Mafk\n",
    "0.909838090472\n",
    "Max\n",
    "0.915759746733\n",
    "Pou2f2\n",
    "0.93228627328\n",
    "Rxra\n",
    "0.714333611668\n",
    "Sp1\n",
    "0.887451495053\n",
    "Srf\n",
    "0.913463596107\n",
    "Tbp\n",
    "0.650860624848\n",
    "Tcf7l2\n",
    "0.849462619421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = my_model.get_fscore()\n",
    "importance_frame = pd.DataFrame({'Importance': list(importances.values()), 'Feature': list(importances.keys())})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame.plot(kind = 'barh', x = 'Feature', figsize = (8,8), color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select features using threshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "thresholds = np.sort(my_model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "\t# select features using threshold\n",
    "\tselection = SelectFromModel(my_model, threshold=thresh, prefit=True)\n",
    "\tselect_X_train = selection.transform(X_train)\n",
    "\t# train model\n",
    "\tselection_model = XGBClassifier()\n",
    "\tselection_model.fit(select_X_train, y_train)\n",
    "\t# eval model\n",
    "\tselect_X_test = selection.transform(X_test)\n",
    "\ty_pred = selection_model.predict(select_X_test)\n",
    "\tpredictions = [round(value) for value in y_pred]\n",
    "\taccuracy = accuracy_score(y_test, predictions)\n",
    "\tprint(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?my_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_name\tAUC\tAUPRC\t\n",
    "Ap2 0.938124646676 0.932824727415\n",
    "kmer_score 0.555311297813 max_kmer_score 0.83264440124 roll_shape 0.583816820508 max_kmer_score_pos 0.735638915265 dn_hg_score 0.379098841749 dn_hg_score2 0.401589110449 dnase 0.768382748196 roll_shape 0.583816820508\n",
    "Hnf4a\n",
    "AUC 0.937684911264\n",
    "AUPRC 0.939223332641\n",
    "Arid3a\n",
    "AUC 0.860919620246\n",
    "AUPRC 0.852510683225\n",
    "Tbp\n",
    "AUC 0.770311691142\n",
    "AUPRC 0.74088930107\n",
    "Elk1\n",
    "AUC 0.948405633803\n",
    "AUPRC 0.952530567524\n",
    "Elk4\n",
    "AUC 0.935527082941\n",
    "AUPRC 0.944097868824\n",
    "Gata3\n",
    "AUC 0.868914046639\n",
    "AUPRC 0.872456804545\n",
    "Irf3\n",
    "AUC 0.913135367151\n",
    "AUPRC 0.885632142802\n",
    "Srf\n",
    "AUC 0.852947590172\n",
    "AUPRC 0.855429325735\n",
    "Tcf7l2\n",
    "AUC 0.810775240055\n",
    "AUPRC 0.819769318345\n",
    "Pou2f2\n",
    "AUC 0.884103094753\n",
    "AUPRC 0.880243202566\n",
    "Egr1\n",
    "AUC 0.853968119074\n",
    "AUPRC 0.865720123554\n",
    "Rxra\n",
    "AUC 0.691017656202\n",
    "AUPRC 0.661511909179\n",
    "Ets1\n",
    "AUC 0.866551530778\n",
    "AUPRC 0.856931625276\n",
    "Mafk\n",
    "AUC 0.902584755547\n",
    "AUPRC 0.907614209914\n",
    "Max\n",
    "AUC 0.887020126969\n",
    "AUPRC 0.876736817766\n",
    "max\n",
    "AUC 0.883304042534\n",
    "AUPRC 0.869888988934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next steps in predictions\n",
    "1. Create an additional; feature, that uses the best PWM for prediction. This should would be used during the comparison stage, to show how this model performs compared with a pwm model. We can also compare it with the pure k-mer scoring. \n",
    "2. An additional thing to validate or argue in my thesis is the value of the k-mer scoring approach being used. I need to campare the few approaches I can come across on their own. This could later be moved to chapter three or something. \n",
    "3. If time allows, how hard would it be for me to include a DNAshape feature to my model as well?\n",
    "4. When I have multiple features to work with, how can I choose te most predictive features? The number of features that would have optimal performance. \n",
    "    - Here is where recursive feature elimination may be of some use\n",
    "5. What else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_frame.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max using 2000 each for all the features\n",
    "AUC 0.9342615\n",
    "AUPRC 0.924861874448\n",
    "\n",
    "max using a but the dnase feature with 4000\n",
    "AUC 0.897419625\n",
    "AUPRC 0.892977974024\n",
    "\n",
    "\n",
    "max with all but two\n",
    "AUC 0.914374375\n",
    "AUPRC 0.90579930936\n",
    "\n",
    "max for all after changing the scoing function to Energy score\n",
    "AUC 0.941812875\n",
    "AUPRC 0.93820425951\n",
    "\n",
    "\n",
    "max\n",
    "AUC 0.850881613639\n",
    "AUPRC 0.834658458345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Foxa2\n",
    "AUC 0.999999910074\n",
    "AUPRC 0.999999910089\n",
    "Gata3\n",
    "AUC 0.760884285762\n",
    "AUPRC 0.770112301698\n",
    "Max\n",
    "AUC 0.781464160056\n",
    "AUPRC 0.782942410112\n",
    "Tcf3\n",
    "AUC 0.999999994111\n",
    "AUPRC 0.999999994111\n",
    "Tcf7l2\n",
    "AUC 0.69594951989\n",
    "AUPRC 0.72373955393\n",
    "Irf3\n",
    "AUC 0.727478245484\n",
    "AUPRC 0.705951576425\n",
    "Irf4\n",
    "AUC 1.0\n",
    "AUPRC 1.0\n",
    "Hnf4a\n",
    "AUC 0.891285263782\n",
    "AUPRC 0.893551459953\n",
    "Nr2f2\n",
    "AUC 1.0\n",
    "AUPRC 1.0\n",
    "Rxra\n",
    "AUC 0.521916302461\n",
    "AUPRC 0.513172289063\n",
    "Egr1\n",
    "AUC 0.801586154663\n",
    "AUPRC 0.821077919551\n",
    "Sp4\n",
    "AUC 0.999999963477\n",
    "AUPRC 0.999999963487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tf in tf_list:\n",
    "    print tf\n",
    "    print get_contigmers(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.849744185417\n",
    "0.840914583636\n",
    "\n",
    "0.851139224626\n",
    "0.847959778538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.fit(feature_frame, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9]}\n",
    "ind_params = {'n_estimators': 1000, 'seed':0, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth': 3, 'min_child_weight': 1}\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "optimized_GBM.fit(feature_frame, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Egr1\n",
    "\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'subsample': [0.7, 0.8, 0.9], 'learning_rate': [0.1, 0.01]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)\n",
    "\n",
    "[mean: 0.82907, std: 0.02203, params: {'max_depth': 3, 'min_child_weight': 1},\n",
    " mean: 0.82895, std: 0.02155, params: {'max_depth': 3, 'min_child_weight': 3},\n",
    " mean: 0.82891, std: 0.02206, params: {'max_depth': 3, 'min_child_weight': 5},\n",
    " mean: 0.82663, std: 0.02266, params: {'max_depth': 5, 'min_child_weight': 1},\n",
    " mean: 0.82706, std: 0.02249, params: {'max_depth': 5, 'min_child_weight': 3},\n",
    " mean: 0.82644, std: 0.02345, params: {'max_depth': 5, 'min_child_weight': 5},\n",
    " mean: 0.82056, std: 0.02175, params: {'max_depth': 7, 'min_child_weight': 1},\n",
    " mean: 0.81939, std: 0.02062, params: {'max_depth': 7, 'min_child_weight': 3},\n",
    " mean: 0.82089, std: 0.02104, params: {'max_depth': 7, 'min_child_weight': 5}]\n",
    "\n",
    "\n",
    "GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'subsample': [0.7, 0.8, 0.9], 'learning_rate': [0.1, 0.01]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)\n",
    "\n",
    "#learning rate\n",
    "\n",
    "[mean: 0.82960, std: 0.02174, params: {'subsample': 0.7, 'learning_rate': 0.1},\n",
    " mean: 0.82907, std: 0.02203, params: {'subsample': 0.8, 'learning_rate': 0.1},\n",
    " mean: 0.82858, std: 0.02144, params: {'subsample': 0.9, 'learning_rate': 0.1},\n",
    " mean: 0.82084, std: 0.01890, params: {'subsample': 0.7, 'learning_rate': 0.01},\n",
    " mean: 0.82065, std: 0.01878, params: {'subsample': 0.8, 'learning_rate': 0.01},\n",
    " mean: 0.82001, std: 0.01869, params: {'subsample': 0.9, 'learning_rate': 0.01}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimized_GBM.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_frame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgdmat = xgb.DMatrix(feature_frame, y_train) # Create our DMatrix to make XGBoost more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':1} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#my_model = train_xgboost(feature_frame[[\"max_kmer_score\",\"dn_hg_score2\"]], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score a different set of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # Predict using our testdmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All: 0.80158615466250405\n",
    "#kmer_pos, dnhg2: 0.76260659391564956\n",
    "\n",
    "0.78146416005633035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scikitlearn_calc_auPRC(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_auc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.94205975000000008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing other machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_frame, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Scale teh train data \n",
    "scaler.fit(feature_frame)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "#Scale the test data as well\n",
    "scaler.fit(X_test)  # Don't cheat - fit only on training data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_svm = clf.predict(X_test)\n",
    "print accuracy_score(y_test, pred_svm)\n",
    "print classification_report(y_test, pred_svm)\n",
    "print auc(y_test, pred_svm, reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print accuracy_score(y_test, pred_svm)\n",
    "print classification_report(y_test, pred_svm)\n",
    "print auc(y_test, pred_svm, reorder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print classification_report(y_pred, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature_frame_p = pd.DataFrame(E_score_combined_p, columns=[\"kmer_score\"])\n",
    "# feature_frame_p [\"max_kmer_score\"] = max_score_combined_p\n",
    "# feature_frame_p[\"dn_hg_score\"] = dn_hg_score_combined_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the created model to predict in a new set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?auc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.44995198267861269\n",
    "0.47816105128731579\n",
    "0.47820144111756235\n",
    "0.55134305136743933\n",
    "0.47282382799312472\n",
    "0.50361321107811818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jaspar_pssm(jaspar, bool_id=True):\n",
    "    \"\"\" \n",
    "    \n",
    "    Construct the PSSM from the JASPAR ID or JASPAR formatted file.\n",
    "\n",
    "    We assume that we are using profiles from the CORE JASPAR db when providing\n",
    "    a JASPAR ID. Hence the JASPAR ID should starts with 'MA'.\n",
    "    If a filename is provided, we assume that the TF binding profile is using\n",
    "    the JASPAR format as documented in the Bio.motifs.jaspar BioPython module.\n",
    "    \n",
    "    \"\"\"\n",
    "    import Bio.motifs\n",
    "    if bool_id:\n",
    "        from Bio.motifs.jaspar.db import JASPAR5\n",
    "        # Please put your local JASPAR database information below\n",
    "        jaspar_db_host = \"\"\n",
    "        jaspar_db_name = \"\"\n",
    "        jaspar_db_user = \"\"\n",
    "        jaspar_db_pass = \"\"\n",
    "        jdb = JASPAR5(host=jaspar_db_host, name=jaspar_db_name,\n",
    "                      user=jaspar_db_user, password=jaspar_db_pass)\n",
    "        motif = jdb.fetch_motif_by_id(jaspar)\n",
    "        motif.pseudocounts = Bio.motifs.jaspar.calculate_pseudocounts(motif)\n",
    "    else:\n",
    "        with open(jaspar) as handle:\n",
    "            motif = Bio.motifs.read(handle, 'jaspar')\n",
    "            # If the PFM contains a zero, need to use pseudocounts\n",
    "            if contains_zero(motif):\n",
    "                import sys\n",
    "                # The pseudocount will be minimal\n",
    "                motif.pseudocounts = sys.float_info.min\n",
    "    return motif.pssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pssm = get_jaspar_pssm(\"MA0466.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pssm_hits(pssm, seq_file):\n",
    "    \"\"\" Predict hits in sequences using a PSSM. \"\"\"\n",
    "    from operator import itemgetter\n",
    "    import math\n",
    "    import Bio.SeqIO\n",
    "    from Bio.Alphabet import generic_dna\n",
    "    from Bio.Alphabet.IUPAC import IUPACUnambiguousDNA as unambiguousDNA\n",
    "    import tffm_module\n",
    "    from hit_module import HIT\n",
    "    hits = []\n",
    "    for record in Bio.SeqIO.parse(seq_file, \"fasta\", generic_dna):\n",
    "        record.seq.alphabet = unambiguousDNA()\n",
    "        scores = [(pos, ((score - pssm.min) / (pssm.max - pssm.min)))\n",
    "                  for pos, score in pssm.search(record.seq, pssm.min) if not\n",
    "                  math.isnan(score)]\n",
    "        if scores:\n",
    "            pos_maxi, maxi = max(scores, key=itemgetter(1))\n",
    "            strand = \"+\"\n",
    "            if pos_maxi < 0:\n",
    "                strand = \"-\"\n",
    "                pos_maxi = pos_maxi + len(record.seq)\n",
    "            hits.append(HIT(record, pos_maxi + 1, pos_maxi + pssm.length,\n",
    "                            strand, maxi))\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_learning_data(feature_frame, pos_size, neg_size):\n",
    "    \"\"\"\n",
    "    Given a pandas dataframe with the features,\n",
    "    \"\"\"\n",
    "    \n",
    "    #import pandas as pd\n",
    "    #import numpy as np\n",
    "    #from sklearn.datasets import dump_svmlight_file\n",
    "    \n",
    "    y = np.concatenate((np.ones(pos_size), np.ones(neg_size)*-1), axis=0)\n",
    "\n",
    "    target = pd.Series.from_array(y)\n",
    "    target = target.apply(int)\n",
    "    target = target.to_frame(name=\"Target\")\n",
    "    \n",
    "    target_f1 = feature_frame.T.append(target.T).T\n",
    "\n",
    "\n",
    "    cutoff = target_f1.count()[0]\n",
    "\n",
    "    ids = pd.Series.from_array(np.arange(1, cutoff+1))\n",
    "    ids = ids.apply(int)\n",
    "\n",
    "    target_f1 = target_f1.T.append(ids.to_frame(name=\"Id\").T).T\n",
    "\n",
    "\n",
    "    X = target_f1[np.setdiff1d(target_f1.columns,['Id','Target'])]\n",
    "    y = target_f1.Target\n",
    "    \n",
    "    return target_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are very disappointing performaces. Why so? Is it a failure in the scorin functions, the k-mers or the model, of the choice of negative sequences? What would happen if we added more features? Which features would these be? So, what then is the next step:\n",
    "- Expand my features to include PWM\n",
    "- Use the maximum k-mer score rather than the sum\n",
    "- test a different TFs\n",
    "- make the pos and negative set equal\n",
    "- Include counts in frequency difference directly, sclalled in the same way as E-scores\n",
    "- Test other machine learning aprroaches like SVM\n",
    "- Use a k-mer model from kmerSVM and use it to score the sequences\n",
    "\n",
    "Write up on what we will have learned so far. Spend the morning implementing the above and the afternoon in the cafe, writing up on where I am so far, especially the introduction and metholology section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put any code I do not need here. Remove anything that is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Using the Xgboost model to predict on the test data\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "# print \"Using the model to predict on the ladder data\"\n",
    "\n",
    "# testdmat = xgb.DMatrix(hdf_scores_lad)\n",
    "# y_pred = final_gb.predict(testdmat) # Predict using our testdmat\n",
    "\n",
    "# print \"Saving the model for latter reference\"\n",
    "\n",
    "# #plot_feature_importance(final_gb, \"%s/annotations/%s/%s_features.png\" % (BASE_DIR, tfs, tfs))\n",
    "# np.savetxt(\"%s/annotations/%s/%s_xgb_v2.txt\" % (BASE_DIR, tfs,tfs), y_pred)\n",
    "\n",
    "# joblib.dump(final_gb, \"%s/annotations/%s/%s_xgboost_v2.dat\" % (BASE_DIR, tfs, tfs))\n",
    "\n",
    "\n",
    "# tau_score = pd.read_table(\"/home/kipkurui/Project/PBM_DNase/Results/PBM_Reranked/Gata3/Gata3_4964.2_deBruijn_8mers_combined.txt\")\n",
    "# tau = pd.read_table(\"/home/kipkurui/Project/Others_work/Bayesian_PBM_Analysis/Bayesian_PBM_Analysis/background_example/reweighed.txt\", header=None)\n",
    "\n",
    "# tau_score[\"E-score\"] = tau\n",
    "# tau_score.to_csv(\"rewighed_hg_dn_scores\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epeats = pd.read_table(\"/home/kipkurui/Project/PBM_DNase/Data/DNase/wgEncodeRegDnaseClusteredV3.bed\", header=None)\n",
    "repeats = pd.read_table(\"/home/kipkurui/Project/PBM_DNase/Data/DNase/wgEncodeRegDnaseClusteredV3_bed.bed\", header=None)\n",
    "repeats = pybedtools.BedTool.from_dataframe(repeats)\n",
    "#     if len(dfs) > 2000:\n",
    "#         get_top = 2000\n",
    "#     else:\n",
    "#         get_top = len(dfs)\n",
    "a = pybedtools.BedTool.from_dataframe(combined_bed)\n",
    "\n",
    "#test = a.subtract(repeats, A=True)\n",
    "#my_df = a.intersect(repeats, c=True, -f=0.5).to_dataframe()\n",
    "#return test.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trim_to_p = min(len(pos_bed_p), len(neg_bed_p))\n",
    "# #trim_to_p = 2000\n",
    "# pos_bed_p = pos_bed_p.head(trim_to_p)\n",
    "# neg_bed_p = neg_bed_p.head(trim_to_p)\n",
    "\n",
    "# combined_bed_p = pos_bed_p.append(neg_bed_p, ignore_index=True)\n",
    "\n",
    "# E_score_combined_p = get_kmer_score(combined_bed_p, energy_score_kmer, E_score_dict)\n",
    "# max_score_combined_p = get_kmer_score(combined_bed_p, max_score_kmer, E_score_dict)\n",
    "# dn_hg_score_combined2_p = get_kmer_score(combined_bed_p, max_score_kmer, dn_hg_dict2)\n",
    "# dn_hg_score_combined_p = get_kmer_score(combined_bed_p, max_score_kmer, dn_hg_dict)\n",
    "# dnase_scores_p = apply_get_max_dnase(combined_bed_p)\n",
    "\n",
    "# feature_frame_p = pd.DataFrame(E_score_combined_p, columns=[\"kmer_score\"])\n",
    "# feature_frame_p [\"max_kmer_score\"] = max_score_combined_p\n",
    "# feature_frame_p[\"dn_hg_score\"] = dn_hg_score_combined_p\n",
    "# feature_frame_p[\"dn_hg_score2\"] = dn_hg_score_combined2_p\n",
    "# feature_frame_p[\"dnase\"] = dnase_scores_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
